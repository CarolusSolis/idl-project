{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NISmMIaQCGqi"
      },
      "source": [
        "# Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34LtYmy7Etqz",
        "outputId": "d6d55041-447a-46e0-a17f-6b205e38b73c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Apr 25 05:22:18 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   74C    P8              12W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install insightface==0.2.1 onnxruntime moviepy\n",
        "!pip install onnxruntime-gpu\n"
      ],
      "metadata": {
        "id": "Rjde-jdnHbYR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install googledrivedownloader\n",
        "!pip install imageio==2.4.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9MX7tZjQGI0",
        "outputId": "ac111204-d20c-463b-9960-5caf11ff34d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: googledrivedownloader in /usr/local/lib/python3.10/dist-packages (0.4)\n",
            "Collecting imageio==2.4.1\n",
            "  Downloading imageio-2.4.1.tar.gz (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from imageio==2.4.1) (1.23.5)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from imageio==2.4.1) (9.4.0)\n",
            "Building wheels for collected packages: imageio\n",
            "  Building wheel for imageio (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for imageio: filename=imageio-2.4.1-py3-none-any.whl size=3303885 sha256=64af7004994d2eeb3a72f10731feedc3b575466b1420f618a7fa428d354df357\n",
            "  Stored in directory: /root/.cache/pip/wheels/96/5d/ce/bdbdb04744dac03906336eb0d01ff1e222061d3419c55c55f9\n",
            "Successfully built imageio\n",
            "Installing collected packages: imageio\n",
            "  Attempting uninstall: imageio\n",
            "    Found existing installation: imageio 2.31.6\n",
            "    Uninstalling imageio-2.31.6:\n",
            "      Successfully uninstalled imageio-2.31.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "moviepy 1.0.3 requires imageio<3.0,>=2.5; python_version >= \"3.4\", but you have imageio 2.4.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed imageio-2.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download face detection model"
      ],
      "metadata": {
        "id": "xM6nS3EOps7X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## You can upload filed manually\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')\n",
        "\n",
        "### Now onedrive file can be downloaded in Colab directly!\n",
        "### If the link blow is not permanent, you can just download it from the\n",
        "### open url(can be found at [our repo]/doc/guidance/preparation.md) and copy the assigned download link here.\n",
        "### many thanks to woctezuma for this very useful help\n",
        "!wget --no-check-certificate \"https://sh23tw.dm.files.1drv.com/y4mmGiIkNVigkSwOKDcV3nwMJulRGhbtHdkheehR5TArc52UjudUYNXAEvKCii2O5LAmzGCGK6IfleocxuDeoKxDZkNzDRSt4ZUlEt8GlSOpCXAFEkBwaZimtWGDRbpIGpb_pz9Nq5jATBQpezBS6G_UtspWTkgrXHHxhviV2nWy8APPx134zOZrUIbkSF6xnsqzs3uZ_SEX_m9Rey0ykpx9w\" -O antelope.zip\n",
        "!unzip ./antelope.zip -d ./insightface_func/models/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57q6dn_rQSfe",
        "outputId": "1869d4a6-cac8-4d5f-ceae-6b706ab40a13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-04-25 03:16:32--  https://sh23tw.dm.files.1drv.com/y4mmGiIkNVigkSwOKDcV3nwMJulRGhbtHdkheehR5TArc52UjudUYNXAEvKCii2O5LAmzGCGK6IfleocxuDeoKxDZkNzDRSt4ZUlEt8GlSOpCXAFEkBwaZimtWGDRbpIGpb_pz9Nq5jATBQpezBS6G_UtspWTkgrXHHxhviV2nWy8APPx134zOZrUIbkSF6xnsqzs3uZ_SEX_m9Rey0ykpx9w\n",
            "Resolving sh23tw.dm.files.1drv.com (sh23tw.dm.files.1drv.com)... 13.107.42.12\n",
            "Connecting to sh23tw.dm.files.1drv.com (sh23tw.dm.files.1drv.com)|13.107.42.12|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 248024513 (237M) [application/zip]\n",
            "Saving to: ‘antelope.zip’\n",
            "\n",
            "antelope.zip         96%[==================> ] 228.17M  36.8MB/s    in 6.1s    \n",
            "\n",
            "2024-04-25 03:16:39 (37.1 MB/s) - Read error at byte 239254573/248024513 (Connection reset by peer). Retrying.\n",
            "\n",
            "--2024-04-25 03:16:40--  (try: 2)  https://sh23tw.dm.files.1drv.com/y4mmGiIkNVigkSwOKDcV3nwMJulRGhbtHdkheehR5TArc52UjudUYNXAEvKCii2O5LAmzGCGK6IfleocxuDeoKxDZkNzDRSt4ZUlEt8GlSOpCXAFEkBwaZimtWGDRbpIGpb_pz9Nq5jATBQpezBS6G_UtspWTkgrXHHxhviV2nWy8APPx134zOZrUIbkSF6xnsqzs3uZ_SEX_m9Rey0ykpx9w\n",
            "Connecting to sh23tw.dm.files.1drv.com (sh23tw.dm.files.1drv.com)|13.107.42.12|:443... connected.\n",
            "HTTP request sent, awaiting response... 206 Partial Content\n",
            "Length: 248024513 (237M), 8769940 (8.4M) remaining [application/zip]\n",
            "Saving to: ‘antelope.zip’\n",
            "\n",
            "antelope.zip        100%[+++++++++++++++++++>] 236.53M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2024-04-25 03:16:41 (73.4 MB/s) - ‘antelope.zip’ saved [248024513/248024513]\n",
            "\n",
            "Archive:  ./antelope.zip\n",
            "   creating: ./insightface_func/models/antelope/\n",
            "  inflating: ./insightface_func/models/antelope/glintr100.onnx  \n",
            "  inflating: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -P ./arcface_model https://github.com/neuralchen/SimSwap/releases/download/1.0/arcface_checkpoint.tar\n",
        "!wget https://github.com/neuralchen/SimSwap/releases/download/1.0/checkpoints.zip\n",
        "!unzip ./checkpoints.zip  -d ./checkpoints"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_jW7BLaTn_F",
        "outputId": "6f8e616d-0a2b-4834-8ad7-f6413860f366"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-04-25 03:31:12--  https://github.com/neuralchen/SimSwap/releases/download/1.0/arcface_checkpoint.tar\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/374891081/f01468b3-446b-4867-8c78-6d496183f9e6?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240425%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240425T033113Z&X-Amz-Expires=300&X-Amz-Signature=f81acdb5bce3b4f9b06bead0c15f39d72324a0558b8110fc07f6dbb6033d59ca&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=374891081&response-content-disposition=attachment%3B%20filename%3Darcface_checkpoint.tar&response-content-type=application%2Foctet-stream [following]\n",
            "--2024-04-25 03:31:13--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/374891081/f01468b3-446b-4867-8c78-6d496183f9e6?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240425%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240425T033113Z&X-Amz-Expires=300&X-Amz-Signature=f81acdb5bce3b4f9b06bead0c15f39d72324a0558b8110fc07f6dbb6033d59ca&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=374891081&response-content-disposition=attachment%3B%20filename%3Darcface_checkpoint.tar&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 209280521 (200M) [application/octet-stream]\n",
            "Saving to: ‘./arcface_model/arcface_checkpoint.tar.1’\n",
            "\n",
            "arcface_checkpoint. 100%[===================>] 199.58M   331MB/s    in 0.6s    \n",
            "\n",
            "2024-04-25 03:31:14 (331 MB/s) - ‘./arcface_model/arcface_checkpoint.tar.1’ saved [209280521/209280521]\n",
            "\n",
            "--2024-04-25 03:31:14--  https://github.com/neuralchen/SimSwap/releases/download/1.0/checkpoints.zip\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/374891081/a8dac400-dcb6-11eb-933f-977cd7f5f554?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240425%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240425T033114Z&X-Amz-Expires=300&X-Amz-Signature=5003b6aeaff58fb6b32dd811cddb6913c47a6b6e13a589f8c7caf63f13cd4b83&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=374891081&response-content-disposition=attachment%3B%20filename%3Dcheckpoints.zip&response-content-type=application%2Foctet-stream [following]\n",
            "--2024-04-25 03:31:14--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/374891081/a8dac400-dcb6-11eb-933f-977cd7f5f554?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240425%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240425T033114Z&X-Amz-Expires=300&X-Amz-Signature=5003b6aeaff58fb6b32dd811cddb6913c47a6b6e13a589f8c7caf63f13cd4b83&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=374891081&response-content-disposition=attachment%3B%20filename%3Dcheckpoints.zip&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 256461775 (245M) [application/octet-stream]\n",
            "Saving to: ‘checkpoints.zip’\n",
            "\n",
            "checkpoints.zip     100%[===================>] 244.58M   340MB/s    in 0.7s    \n",
            "\n",
            "2024-04-25 03:31:15 (340 MB/s) - ‘checkpoints.zip’ saved [256461775/256461775]\n",
            "\n",
            "Archive:  ./checkpoints.zip\n",
            "   creating: ./checkpoints/people/\n",
            "  inflating: ./checkpoints/people/iter.txt  \n",
            "  inflating: ./checkpoints/people/latest_net_D1.pth  \n",
            "  inflating: ./checkpoints/people/latest_net_D2.pth  \n",
            "  inflating: ./checkpoints/people/latest_net_G.pth  \n",
            "  inflating: ./checkpoints/people/loss_log.txt  \n",
            "  inflating: ./checkpoints/people/opt.txt  \n",
            "   creating: ./checkpoints/people/web/\n",
            "   creating: ./checkpoints/people/web/images/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !wget -P ./parsing_model/checkpoint https://github.com/neuralchen/SimSwap/releases/download/1.0/79999_iter.pth"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yw_5sZ41Rgg5",
        "outputId": "eb0b4b49-6712-4b75-981b-5e1af1f9167a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-04-25 03:21:51--  https://github.com/neuralchen/SimSwap/releases/download/1.0/79999_iter.pth\n",
            "Resolving github.com (github.com)... 140.82.112.4\n",
            "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/374891081/6f43c2ff-c59c-48ad-9854-392249307d00?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240425%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240425T032151Z&X-Amz-Expires=300&X-Amz-Signature=b55b48674a6e6ed7168c7d6183e5615de8c68ff9edc278fde95606a1206433ed&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=374891081&response-content-disposition=attachment%3B%20filename%3D79999_iter.pth&response-content-type=application%2Foctet-stream [following]\n",
            "--2024-04-25 03:21:51--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/374891081/6f43c2ff-c59c-48ad-9854-392249307d00?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240425%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240425T032151Z&X-Amz-Expires=300&X-Amz-Signature=b55b48674a6e6ed7168c7d6183e5615de8c68ff9edc278fde95606a1206433ed&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=374891081&response-content-disposition=attachment%3B%20filename%3D79999_iter.pth&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 53289463 (51M) [application/octet-stream]\n",
            "Saving to: ‘./parsing_model/checkpoint/79999_iter.pth’\n",
            "\n",
            "79999_iter.pth      100%[===================>]  50.82M   290MB/s    in 0.2s    \n",
            "\n",
            "2024-04-25 03:21:51 (290 MB/s) - ‘./parsing_model/checkpoint/79999_iter.pth’ saved [53289463/53289463]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set path"
      ],
      "metadata": {
        "id": "lxok2XJ9qCUC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd idl-project/SimSwap"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-EHXcFvFY6O",
        "outputId": "7da27a9b-6582-4c4e-9749-fe4390fc9361"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/idl-project/SimSwap\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7XAeVttyjZIJ",
        "outputId": "37ade3e0-8b1d-4319-d72c-ac94db8d8094"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " antelope.zip           \u001b[0m\u001b[01;34mresults-eca\u001b[0m/\n",
            " \u001b[01;34marcface_model\u001b[0m/         \u001b[01;34mresults-simswap\u001b[0m/\n",
            " \u001b[01;34mcheckpoints\u001b[0m/           \u001b[01;34mresults-ssim\u001b[0m/\n",
            " checkpoints.zip        shape_predictor_68_face_landmarks.dat\n",
            " cog.yaml              'SimSwap colab.ipynb'\n",
            " \u001b[01;34mcombined_images\u001b[0m/       \u001b[01;34msimswaplogo\u001b[0m/\n",
            " \u001b[01;34mcrop_224\u001b[0m/              \u001b[01;34msource\u001b[0m/\n",
            " \u001b[01;34mdata\u001b[0m/                  source.zip\n",
            " \u001b[01;34mdemo_file\u001b[0m/             \u001b[01;34mtarget\u001b[0m/\n",
            " \u001b[01;34mdocs\u001b[0m/                  target.zip\n",
            " \u001b[01;32mdownload-weights.sh\u001b[0m*   test_one_image.py\n",
            " \u001b[01;34minsightface_func\u001b[0m/      test_video_swapmulti.py\n",
            " LICENSE                test_video_swap_multispecific.py\n",
            " \u001b[01;34m__MACOSX\u001b[0m/              test_video_swapsingle.py\n",
            " \u001b[01;34mmodels\u001b[0m/                test_video_swapspecific.py\n",
            " MultiSpecific.ipynb    test_wholeimage_swapmulti.py\n",
            " \u001b[01;34moptions\u001b[0m/               test_wholeimage_swap_multispecific.py\n",
            " \u001b[01;34moutput\u001b[0m/                test_wholeimage_swapsingle.py\n",
            " \u001b[01;34mparsing_model\u001b[0m/         test_wholeimage_swapspecific.py\n",
            " \u001b[01;34mpeople\u001b[0m/                \u001b[01;34mtmp\u001b[0m/\n",
            " \u001b[01;34mpg_modules\u001b[0m/            train.ipynb\n",
            " predict.py             train.py\n",
            " README.md              \u001b[01;34mutil\u001b[0m/\n",
            " \u001b[01;34mresults\u001b[0m/               \u001b[01;34mwandb\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download checkpoints"
      ],
      "metadata": {
        "id": "6pCxFzL2qE7o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown"
      ],
      "metadata": {
        "id": "yKtoFFMRlXXo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample code for downloading one model extension checkpoint based on the google drive share link\n",
        "# gdown.download_folder(\"https://drive.google.com/drive/u/1/folders/1Gd5gGi1g4EmX05KbH3wJbzcyrQaoVPg2\", quiet=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MxZJC9CjlSd7",
        "outputId": "c8bdc0de-de5f-44f0-ac1b-5cf6aba72eb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/idl-project/SimSwap/eca/64000_net_D.pth',\n",
              " '/content/idl-project/SimSwap/eca/64000_net_G.pth',\n",
              " '/content/idl-project/SimSwap/eca/64000_optim_D.pth',\n",
              " '/content/idl-project/SimSwap/eca/64000_optim_G.pth']"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sample code for single face swap with checkpoint"
      ],
      "metadata": {
        "id": "nPn3bD_AqPG_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uu8bJ5RaCGqk",
        "outputId": "12a921df-c363-40d2-864f-7558c429ff54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: people\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./output/people/\n",
            "phase: test\n",
            "pic_a_path: ./demo_file/specific1.png\n",
            "pic_b_path: ./demo_file/specific3.png\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: latest\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n"
          ]
        }
      ],
      "source": [
        "\"\"\"sample command for a single swap\"\"\"\n",
        "# see https://github.com/neuralchen/SimSwap/blob/main/docs/guidance/usage.md\n",
        "\n",
        "baseline_command = (\n",
        "    \"python test_wholeimage_swapsingle.py \"\n",
        "    \"--crop_size 224 \"\n",
        "    \"--use_mask \"\n",
        "    \"--name people \" # this is the name of the checkpoint folder with model (ex. perceptual-loss-1)\n",
        "    \"--Arc_path arcface_model/arcface_checkpoint.tar \"\n",
        "    \"--pic_a_path ./demo_file/specific1.png \" # source image\n",
        "    \"--pic_b_path ./demo_file/specific3.png \" # target image\n",
        "    \"--output_path ./output/people/ \"\n",
        "    \"--which_epoch latest \" # this is the epoch number of the model to use (ex. 75000 )\n",
        "    \"--checkpoints_dir checkpoints/\"\n",
        ")\n",
        "\n",
        "!{baseline_command}\n",
        "\n",
        "# !python test_wholeimage_swapsingle.py -h\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"sample command for a single swap\"\"\"\n",
        "# see https://github.com/neuralchen/SimSwap/blob/main/docs/guidance/usage.md\n",
        "\n",
        "riya_baseline_command = (\n",
        "    \"python test_wholeimage_swapsingle.py \"\n",
        "    \"--crop_size 224 \"\n",
        "    \"--use_mask \"\n",
        "    \"--name Baseline \" # this is the name of the checkpoint folder with model (ex. perceptual-loss-1)\n",
        "    \"--Arc_path arcface_model/arcface_checkpoint.tar \"\n",
        "    \"--pic_a_path ./demo_file/specific1.png \" # source image\n",
        "    \"--pic_b_path ./demo_file/specific3.png \" # target image\n",
        "    \"--output_path ./output/Baseline \"\n",
        "    \"--which_epoch 55000 \" # this is the epoch number of the model to use (ex. 75000 )\n",
        "    \"--checkpoints_dir checkpoints/\"\n",
        ")\n",
        "\n",
        "!{riya_baseline_command}\n",
        "\n",
        "# !python test_wholeimage_swapsingle.py -h\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16tCGIGSjsJo",
        "outputId": "759d50e3-adb3-4ff2-ed89-fdb801040504"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: Baseline\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./output/Baseline\n",
            "phase: test\n",
            "pic_a_path: ./demo_file/specific1.png\n",
            "pic_b_path: ./demo_file/specific3.png\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 55000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"sample command for a single swap\"\"\"\n",
        "# see https://github.com/neuralchen/SimSwap/blob/main/docs/guidance/usage.md\n",
        "\n",
        "eca_baseline_command = (\n",
        "    \"python test_wholeimage_swapsingle.py \"\n",
        "    \"--crop_size 224 \"\n",
        "    \"--use_mask \"\n",
        "    \"--name eca \" # this is the name of the checkpoint folder with model (ex. perceptual-loss-1)\n",
        "    \"--Arc_path arcface_model/arcface_checkpoint.tar \"\n",
        "    \"--pic_a_path ./demo_file/specific1.png \" # source image\n",
        "    \"--pic_b_path ./demo_file/specific3.png \" # target image\n",
        "    \"--output_path ./output/eca/ \"\n",
        "    \"--which_epoch 64000 \" # this is the epoch number of the model to use (ex. 75000 )\n",
        "    \"--checkpoints_dir checkpoints/\"\n",
        ")\n",
        "\n",
        "!{eca_baseline_command}\n",
        "\n",
        "# !python test_wholeimage_swapsingle.py -h\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFZsTFc-lvzG",
        "outputId": "d7f59280-f815-4f3e-8dda-548dfa9e1c8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: eca\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./output/eca/\n",
            "phase: test\n",
            "pic_a_path: ./demo_file/specific1.png\n",
            "pic_b_path: ./demo_file/specific3.png\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 64000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "perceptual_command = (\n",
        "    \"python test_wholeimage_swapsingle.py \"\n",
        "    \"--crop_size 224 \"\n",
        "    \"--use_mask \"\n",
        "    \"--name perceptual-loss-1 \" # this is the name of the checkpoint folder with model (ex. perceptual-loss-1)\n",
        "    \"--Arc_path arcface_model/arcface_checkpoint.tar \"\n",
        "    \"--pic_a_path ./demo_file/specific1.png \" # source image\n",
        "    \"--pic_b_path ./demo_file/specific3.png \" # target image\n",
        "    \"--output_path ./output/perceptual/ \"\n",
        "    \"--which_epoch 75000 \" # this is the epoch number of the model to use (ex. 75000 )\n",
        "    \"--checkpoints_dir checkpoints/\"\n",
        ")\n",
        "\n",
        "!{perceptual_command}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rHoPuoQDU-vX",
        "outputId": "ba16c741-e4e9-4c28-d6e9-a70d9ed702ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./output/perceptual/\n",
            "phase: test\n",
            "pic_a_path: ./demo_file/specific1.png\n",
            "pic_b_path: ./demo_file/specific3.png\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Plot face swaps**"
      ],
      "metadata": {
        "id": "WF-oLK-pmUJX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "# import matplotlib.image as mpimg\n",
        "# import os\n",
        "\n",
        "# # Load the images\n",
        "# image_files = ['/content/idl-project/SimSwap/output/Baseline/Baseline_specific1_to_specific3.jpg',\n",
        "#                '/content/idl-project/SimSwap/output/eca/eca_specific1_to_specific3.jpg',\n",
        "#                '/content/idl-project/SimSwap/output/people/people_specific1_to_specific3.jpg',\n",
        "#                '/content/idl-project/SimSwap/output/perceptual/perceptual-loss-1_specific1_to_specific3.jpg']\n",
        "# images = [mpimg.imread(file) for file in image_files]\n",
        "\n",
        "# # Extract filenames from paths\n",
        "# filenames = [os.path.basename(file) for file in image_files]\n",
        "\n",
        "# # Create a 2x2 grid for plotting\n",
        "# fig, axs = plt.subplots(3, 2, figsize=(10, 15))\n",
        "\n",
        "# # Plot source and target images\n",
        "# source_image = mpimg.imread('/content/idl-project/SimSwap/demo_file/specific1.png')\n",
        "# target_image = mpimg.imread('/content/idl-project/SimSwap/demo_file/specific3.png')\n",
        "\n",
        "# axs[0, 0].imshow(source_image)\n",
        "# axs[0, 0].axis('off')\n",
        "# axs[0, 0].set_title(\"Source\", fontsize=10, pad=10)\n",
        "\n",
        "# axs[0, 1].imshow(target_image)\n",
        "# axs[0, 1].axis('off')\n",
        "# axs[0, 1].set_title(\"Target\", fontsize=10, pad=10)\n",
        "\n",
        "# # Plot each image in the grid\n",
        "# for i in range(len(images)):\n",
        "#     row = (i + 2) // 2\n",
        "#     col = (i + 2) % 2\n",
        "#     axs[row, col].imshow(images[i])\n",
        "#     axs[row, col].axis('off')\n",
        "#     axs[row, col].set_title(filenames[i], fontsize=10, pad=10)\n",
        "\n",
        "# # Hide any empty subplots\n",
        "# if len(images) < 4:\n",
        "#     for i in range(len(images), 4):\n",
        "#         axs.flatten()[i + 2].axis('off')\n",
        "\n",
        "# plt.tight_layout()\n",
        "# plt.show()\n"
      ],
      "metadata": {
        "id": "CoWlW6GknviW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krvJwTrUCGqk"
      },
      "source": [
        "# FID for perceptual loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e388KqnxCGql",
        "outputId": "7cdc5e70-26f3-4f89-8d4d-528c42da905e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: source/895.jpg\n",
            "pic_b_path: target/849.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: source/896.jpg\n",
            "pic_b_path: target/858.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: source/897.jpg\n",
            "pic_b_path: target/859.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: source/899.jpg\n",
            "pic_b_path: target/860.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: source/906.jpg\n",
            "pic_b_path: target/861.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: source/908.jpg\n",
            "pic_b_path: target/862.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: source/909.jpg\n",
            "pic_b_path: target/863.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: source/912.jpg\n",
            "pic_b_path: target/864.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: source/918.jpg\n",
            "pic_b_path: target/865.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: source/919.jpg\n",
            "pic_b_path: target/867.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: source/920.jpg\n",
            "pic_b_path: target/870.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: source/921.jpg\n",
            "pic_b_path: target/871.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: source/922.jpg\n",
            "pic_b_path: target/873.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: source/923.jpg\n",
            "pic_b_path: target/874.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: source/924.jpg\n",
            "pic_b_path: target/875.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: source/925.jpg\n",
            "pic_b_path: target/876.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: source/926.jpg\n",
            "pic_b_path: target/877.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: source/927.jpg\n",
            "pic_b_path: target/888.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: source/930.jpg\n",
            "pic_b_path: target/889.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: source/931.jpg\n",
            "pic_b_path: target/898.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: source/932.jpg\n",
            "pic_b_path: target/900.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: source/933.jpg\n",
            "pic_b_path: target/901.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: source/934.jpg\n",
            "pic_b_path: target/902.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: source/935.jpg\n",
            "pic_b_path: target/903.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: source/936.jpg\n",
            "pic_b_path: target/904.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: source/937.jpg\n",
            "pic_b_path: target/905.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: source/940.jpg\n",
            "pic_b_path: target/907.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: source/941.jpg\n",
            "pic_b_path: target/910.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: source/942.jpg\n",
            "pic_b_path: target/911.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: source/943.jpg\n",
            "pic_b_path: target/913.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: source/944.jpg\n",
            "pic_b_path: target/914.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: source/945.jpg\n",
            "pic_b_path: target/915.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: source/946.jpg\n",
            "pic_b_path: target/916.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: source/947.jpg\n",
            "pic_b_path: target/917.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: source/950.jpg\n",
            "pic_b_path: target/928.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: source/951.jpg\n",
            "pic_b_path: target/929.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: source/952.jpg\n",
            "pic_b_path: target/938.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: source/953.jpg\n",
            "pic_b_path: target/939.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: source/954.jpg\n",
            "pic_b_path: target/948.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: source/955.jpg\n",
            "pic_b_path: target/949.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: source/956.jpg\n",
            "pic_b_path: target/958.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: source/957.jpg\n",
            "pic_b_path: target/959.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: source/968.jpg\n",
            "pic_b_path: target/960.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: source/969.jpg\n",
            "pic_b_path: target/961.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: source/978.jpg\n",
            "pic_b_path: target/962.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: source/979.jpg\n",
            "pic_b_path: target/963.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: source/980.jpg\n",
            "pic_b_path: target/964.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: source/981.jpg\n",
            "pic_b_path: target/965.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: source/982.jpg\n",
            "pic_b_path: target/966.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: source/983.jpg\n",
            "pic_b_path: target/967.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: source/984.jpg\n",
            "pic_b_path: target/970.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: source/985.jpg\n",
            "pic_b_path: target/971.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: source/986.jpg\n",
            "pic_b_path: target/972.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: source/987.jpg\n",
            "pic_b_path: target/973.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: source/990.jpg\n",
            "pic_b_path: target/974.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: source/991.jpg\n",
            "pic_b_path: target/975.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: source/992.jpg\n",
            "pic_b_path: target/976.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: source/993.jpg\n",
            "pic_b_path: target/977.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: source/994.jpg\n",
            "pic_b_path: target/988.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: source/995.jpg\n",
            "pic_b_path: target/989.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: source/996.jpg\n",
            "pic_b_path: target/998.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: source/997.jpg\n",
            "pic_b_path: target/999.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: source/SRC_01.png\n",
            "pic_b_path: target/DST_01.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: source/SRC_02.png\n",
            "pic_b_path: target/DST_02.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: source/SRC_03.png\n",
            "pic_b_path: target/DST_03.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import os\n",
        "import subprocess\n",
        "\n",
        "# Define paths to source and target image folders\n",
        "source_folder = \"source\"\n",
        "target_folder = \"target\"\n",
        "output_folder = \"results\"\n",
        "\n",
        "# Get lists of image files in the source and target folders\n",
        "source_files = sorted([f for f in os.listdir(source_folder) if f.endswith(('.jpg', '.jpeg', '.png'))])\n",
        "target_files = sorted([f for f in os.listdir(target_folder) if f.endswith(('.jpg', '.jpeg', '.png'))])\n",
        "\n",
        "# Ensure the number of source and target images are the same\n",
        "if len(source_files) != len(target_files):\n",
        "    print(\"Error: Number of source and target images do not match.\")\n",
        "    exit(1)\n",
        "\n",
        "\n",
        "# Iterate over each pair of source and target images\n",
        "for source_filename, target_filename in zip(source_files, target_files):\n",
        "    # Construct full paths to source and target images\n",
        "    source_img_path = os.path.join(source_folder, source_filename)\n",
        "    target_img_path = os.path.join(target_folder, target_filename)\n",
        "\n",
        "    # Construct output directory path\n",
        "    output_dir = os.path.join(output_folder, \"\")\n",
        "\n",
        "    # Ensure the output directory exists, if not create it\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Execute your Python script using subprocess\n",
        "    perceptual_command = (\n",
        "    \"python test_wholeimage_swapsingle.py \"\n",
        "    \"--crop_size 224 \"\n",
        "    \"--use_mask \"\n",
        "    \"--name perceptual-loss-1 \" # this is the name of the checkpoint folder with model (ex. perceptual-loss-1)\n",
        "    \"--Arc_path arcface_model/arcface_checkpoint.tar \"\n",
        "    f\"--pic_a_path {source_img_path} \" # source image\n",
        "    f\"--pic_b_path {target_img_path} \" # target image\n",
        "    \"--output_path ./results/ \"\n",
        "    \"--which_epoch 75000 \" # this is the epoch number of the model to use (ex. 75000 )\n",
        "    \"--checkpoints_dir checkpoints/\"\n",
        "    )\n",
        "\n",
        "    !{perceptual_command}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CbNTKAhRCGql",
        "outputId": "0d7eea7d-345c-477e-9464-a35ceb46144f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: target/849.jpg\n",
            "pic_b_path: source/895.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: target/858.jpg\n",
            "pic_b_path: source/896.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: target/859.jpg\n",
            "pic_b_path: source/897.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: target/860.jpg\n",
            "pic_b_path: source/899.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: target/861.jpg\n",
            "pic_b_path: source/906.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: target/862.jpg\n",
            "pic_b_path: source/908.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: target/863.jpg\n",
            "pic_b_path: source/909.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: target/864.jpg\n",
            "pic_b_path: source/912.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: target/865.jpg\n",
            "pic_b_path: source/918.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: target/867.jpg\n",
            "pic_b_path: source/919.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: target/870.jpg\n",
            "pic_b_path: source/920.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: target/871.jpg\n",
            "pic_b_path: source/921.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: target/873.jpg\n",
            "pic_b_path: source/922.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: target/874.jpg\n",
            "pic_b_path: source/923.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: target/875.jpg\n",
            "pic_b_path: source/924.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: target/876.jpg\n",
            "pic_b_path: source/925.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: target/877.jpg\n",
            "pic_b_path: source/926.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: target/888.jpg\n",
            "pic_b_path: source/927.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: target/889.jpg\n",
            "pic_b_path: source/930.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: target/898.jpg\n",
            "pic_b_path: source/931.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: target/900.jpg\n",
            "pic_b_path: source/932.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: target/901.jpg\n",
            "pic_b_path: source/933.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: target/902.jpg\n",
            "pic_b_path: source/934.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: target/903.jpg\n",
            "pic_b_path: source/935.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: target/904.jpg\n",
            "pic_b_path: source/936.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: target/905.jpg\n",
            "pic_b_path: source/937.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: target/907.jpg\n",
            "pic_b_path: source/940.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: target/910.jpg\n",
            "pic_b_path: source/941.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: target/911.jpg\n",
            "pic_b_path: source/942.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: target/913.jpg\n",
            "pic_b_path: source/943.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: target/914.jpg\n",
            "pic_b_path: source/944.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: target/915.jpg\n",
            "pic_b_path: source/945.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: target/916.jpg\n",
            "pic_b_path: source/946.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: target/917.jpg\n",
            "pic_b_path: source/947.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: target/928.jpg\n",
            "pic_b_path: source/950.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: target/929.jpg\n",
            "pic_b_path: source/951.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: target/938.jpg\n",
            "pic_b_path: source/952.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: target/939.jpg\n",
            "pic_b_path: source/953.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: target/948.jpg\n",
            "pic_b_path: source/954.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: target/949.jpg\n",
            "pic_b_path: source/955.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: target/958.jpg\n",
            "pic_b_path: source/956.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: target/959.jpg\n",
            "pic_b_path: source/957.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: target/960.jpg\n",
            "pic_b_path: source/968.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: target/961.jpg\n",
            "pic_b_path: source/969.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: target/962.jpg\n",
            "pic_b_path: source/978.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: target/963.jpg\n",
            "pic_b_path: source/979.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: target/964.jpg\n",
            "pic_b_path: source/980.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: target/965.jpg\n",
            "pic_b_path: source/981.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: target/966.jpg\n",
            "pic_b_path: source/982.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: target/967.jpg\n",
            "pic_b_path: source/983.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: target/970.jpg\n",
            "pic_b_path: source/984.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: target/971.jpg\n",
            "pic_b_path: source/985.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: target/972.jpg\n",
            "pic_b_path: source/986.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: target/973.jpg\n",
            "pic_b_path: source/987.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: target/974.jpg\n",
            "pic_b_path: source/990.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: target/975.jpg\n",
            "pic_b_path: source/991.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: target/976.jpg\n",
            "pic_b_path: source/992.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: target/977.jpg\n",
            "pic_b_path: source/993.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: target/988.jpg\n",
            "pic_b_path: source/994.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: target/989.jpg\n",
            "pic_b_path: source/995.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: target/998.jpg\n",
            "pic_b_path: source/996.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: target/999.jpg\n",
            "pic_b_path: source/997.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: target/DST_01.jpg\n",
            "pic_b_path: source/SRC_01.png\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: target/DST_02.jpg\n",
            "pic_b_path: source/SRC_02.png\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: perceptual-loss-1\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results/\n",
            "phase: test\n",
            "pic_a_path: target/DST_03.jpg\n",
            "pic_b_path: source/SRC_03.png\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 75000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n"
          ]
        }
      ],
      "source": [
        "# do the same thing but flipped\n",
        "import os\n",
        "import subprocess\n",
        "\n",
        "# Define paths to source and target image folders\n",
        "source_folder = \"target\"\n",
        "target_folder = \"source\"\n",
        "output_folder = \"results\"\n",
        "\n",
        "# Get lists of image files in the source and target folders\n",
        "source_files = sorted([f for f in os.listdir(source_folder) if f.endswith(('.jpg', '.jpeg', '.png'))])\n",
        "target_files = sorted([f for f in os.listdir(target_folder) if f.endswith(('.jpg', '.jpeg', '.png'))])\n",
        "\n",
        "# Ensure the number of source and target images are the same\n",
        "if len(source_files) != len(target_files):\n",
        "    print(\"Error: Number of source and target images do not match.\")\n",
        "    exit(1)\n",
        "\n",
        "# Iterate over each pair of source and target images\n",
        "for source_filename, target_filename in zip(source_files, target_files):\n",
        "    # Construct full paths to source and target images\n",
        "    source_img_path = os.path.join(source_folder, source_filename)\n",
        "    target_img_path = os.path.join(target_folder, target_filename)\n",
        "\n",
        "    # Construct output directory path\n",
        "    output_dir = os.path.join(output_folder, \"\")\n",
        "\n",
        "    # Ensure the output directory exists, if not create it\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Execute your Python script using subprocess\n",
        "    perceptual_command = (\n",
        "    \"python test_wholeimage_swapsingle.py \"\n",
        "    \"--crop_size 224 \"\n",
        "    \"--use_mask \"\n",
        "    \"--name perceptual-loss-1 \" # this is the name of the checkpoint folder with model (ex. perceptual-loss-1)\n",
        "    \"--Arc_path arcface_model/arcface_checkpoint.tar \"\n",
        "    f\"--pic_a_path {source_img_path} \" # source image\n",
        "    f\"--pic_b_path {target_img_path} \" # target image\n",
        "    \"--output_path ./results/ \"\n",
        "    \"--which_epoch 75000 \" # this is the epoch number of the model to use (ex. 75000 )\n",
        "    \"--checkpoints_dir checkpoints/\"\n",
        "    )\n",
        "\n",
        "    !{perceptual_command}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "def copy_images(source_dir, target_dir, new_folder_name):\n",
        "    # Create a new folder\n",
        "    new_folder_path = os.path.join(os.getcwd(), new_folder_name)\n",
        "    os.makedirs(new_folder_path, exist_ok=True)\n",
        "\n",
        "    # Copy images from source directory\n",
        "    for root, _, files in os.walk(source_dir):\n",
        "        for file in files:\n",
        "            if file.endswith(('.jpg', '.jpeg', '.png', '.gif')):\n",
        "                src_file_path = os.path.join(root, file)\n",
        "                shutil.copy(src_file_path, new_folder_path)\n",
        "\n",
        "    # Copy images from target directory\n",
        "    for root, _, files in os.walk(target_dir):\n",
        "        for file in files:\n",
        "            if file.endswith(('.jpg', '.jpeg', '.png', '.gif')):\n",
        "                src_file_path = os.path.join(root, file)\n",
        "                shutil.copy(src_file_path, new_folder_path)\n",
        "\n",
        "    print(\"Images copied successfully to\", new_folder_name)\n",
        "\n",
        "# Example usage\n",
        "source_directory = \"source\"\n",
        "target_directory = \"target\"\n",
        "new_folder_name = \"combined_images\"\n",
        "\n",
        "copy_images(source_directory, target_directory, new_folder_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tA740R6rZmHk",
        "outputId": "e253cfd9-bb5b-4811-b208-ae342f6c4633"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Images copied successfully to combined_images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0lXHAEyCGqm"
      },
      "source": [
        "Compute FID between source images and deepfakes"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "OUTPUT_SIMSWAP = \"results\"\n",
        "COMBINED_DIR = \"combined_images\""
      ],
      "metadata": {
        "id": "R_7UZfYLroFE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install clean-fid"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0Lp3VOGr5uW",
        "outputId": "97e254df-f5c9-4635-c00a-9bec2a8e4409"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: clean-fid in /usr/local/lib/python3.10/dist-packages (0.1.35)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from clean-fid) (2.1.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from clean-fid) (0.16.0+cu121)\n",
            "Requirement already satisfied: numpy>=1.14.3 in /usr/local/lib/python3.10/dist-packages (from clean-fid) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from clean-fid) (1.11.4)\n",
            "Requirement already satisfied: tqdm>=4.28.1 in /usr/local/lib/python3.10/dist-packages (from clean-fid) (4.66.1)\n",
            "Requirement already satisfied: pillow>=8.1 in /usr/local/lib/python3.10/dist-packages (from clean-fid) (9.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from clean-fid) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->clean-fid) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->clean-fid) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->clean-fid) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->clean-fid) (2024.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->clean-fid) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->clean-fid) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->clean-fid) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->clean-fid) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->clean-fid) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->clean-fid) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->clean-fid) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->clean-fid) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->clean-fid) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scipy==1.11.1"
      ],
      "metadata": {
        "id": "sWLdRPJsHJor"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqERA1FyCGqm",
        "outputId": "d0487134-6a0c-4e0f-cbab-5339581dfbff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "compute FID between two folders\n",
            "Found 1006 images in the folder results\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "FID results : 100%|██████████| 32/32 [00:22<00:00,  1.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1006 images in the folder combined_images\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "FID combined_images : 100%|██████████| 32/32 [00:20<00:00,  1.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " FID Score: 12.27511634407017\n"
          ]
        }
      ],
      "source": [
        "from cleanfid import fid\n",
        "\n",
        "\n",
        "fake_image_path = OUTPUT_SIMSWAP\n",
        "\n",
        "real_image_path = COMBINED_DIR\n",
        "\n",
        "fid_score = fid.compute_fid(fake_image_path, real_image_path)\n",
        "\n",
        "print(\"\\n FID Score:\", fid_score)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from cleanfid import fid\n",
        "\n",
        "fake_image_path = \"results\"\n",
        "\n",
        "real_image_path = \"combined_images\"\n",
        "\n",
        "from cleanfid import fid\n",
        "clip_score = fid.compute_fid(fake_image_path, real_image_path, mode=\"clean\", model_name=\"clip_vit_b_32\")\n",
        "print(\"Clip Score:\", clip_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCJ-eJ6Yk483",
        "outputId": "18498755-36a2-477c-b6f3-d21f481af196"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "compute FID between two folders\n",
            "Found 1006 images in the folder results\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "FID results : 100%|██████████| 32/32 [00:08<00:00,  3.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1006 images in the folder combined_images\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "FID combined_images : 100%|██████████| 32/32 [00:08<00:00,  3.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clip Score: 9.762704489611593\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FID score for eca"
      ],
      "metadata": {
        "id": "CrZoU-5qBl1y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import subprocess\n",
        "\n",
        "# Define paths to source and target image folders\n",
        "name = \"eca\"\n",
        "source_folder = \"source\"\n",
        "target_folder = \"target\"\n",
        "output_folder = \"results-eca\"\n",
        "epoch_number = 64000\n",
        "\n",
        "# Get lists of image files in the source and target folders\n",
        "source_files = sorted([f for f in os.listdir(source_folder) if f.endswith(('.jpg', '.jpeg', '.png'))])\n",
        "target_files = sorted([f for f in os.listdir(target_folder) if f.endswith(('.jpg', '.jpeg', '.png'))])\n",
        "\n",
        "# Ensure the number of source and target images are the same\n",
        "if len(source_files) != len(target_files):\n",
        "    print(\"Error: Number of source and target images do not match.\")\n",
        "    exit(1)\n",
        "\n",
        "\n",
        "# Iterate over each pair of source and target images\n",
        "for source_filename, target_filename in zip(source_files, target_files):\n",
        "    # Construct full paths to source and target images\n",
        "    source_img_path = os.path.join(source_folder, source_filename)\n",
        "    target_img_path = os.path.join(target_folder, target_filename)\n",
        "\n",
        "    # Construct output directory path\n",
        "    output_dir = os.path.join(output_folder, \"\")\n",
        "\n",
        "    # Ensure the output directory exists, if not create it\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Execute your Python script using subprocess\n",
        "    command = (\n",
        "    \"python test_wholeimage_swapsingle.py \"\n",
        "    \"--crop_size 224 \"\n",
        "    \"--use_mask \"\n",
        "    f\"--name {name} \" # this is the name of the checkpoint folder with model (ex. perceptual-loss-1)\n",
        "    \"--Arc_path arcface_model/arcface_checkpoint.tar \"\n",
        "    f\"--pic_a_path {source_img_path} \" # source image\n",
        "    f\"--pic_b_path {target_img_path} \" # target image\n",
        "    f\"--output_path ./{output_folder}/ \"\n",
        "    f\"--which_epoch {epoch_number} \" # this is the epoch number of the model to use (ex. 75000 )\n",
        "    \"--checkpoints_dir checkpoints/\"\n",
        "    )\n",
        "\n",
        "    !{command}\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c5d2811-506c-4498-8a41-e7b5509e2a90",
        "id": "ysAjRKPKBl1_"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: eca\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results-eca/\n",
            "phase: test\n",
            "pic_a_path: source/895.jpg\n",
            "pic_b_path: target/849.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 64000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: eca\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results-eca/\n",
            "phase: test\n",
            "pic_a_path: source/896.jpg\n",
            "pic_b_path: target/858.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 64000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: eca\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results-eca/\n",
            "phase: test\n",
            "pic_a_path: source/897.jpg\n",
            "pic_b_path: target/859.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 64000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: eca\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results-eca/\n",
            "phase: test\n",
            "pic_a_path: source/899.jpg\n",
            "pic_b_path: target/860.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 64000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: eca\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results-eca/\n",
            "phase: test\n",
            "pic_a_path: source/906.jpg\n",
            "pic_b_path: target/861.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 64000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: eca\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results-eca/\n",
            "phase: test\n",
            "pic_a_path: source/908.jpg\n",
            "pic_b_path: target/862.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 64000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: eca\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results-eca/\n",
            "phase: test\n",
            "pic_a_path: source/909.jpg\n",
            "pic_b_path: target/863.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 64000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: eca\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results-eca/\n",
            "phase: test\n",
            "pic_a_path: source/912.jpg\n",
            "pic_b_path: target/864.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 64000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: eca\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results-eca/\n",
            "phase: test\n",
            "pic_a_path: source/918.jpg\n",
            "pic_b_path: target/865.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 64000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: eca\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results-eca/\n",
            "phase: test\n",
            "pic_a_path: source/919.jpg\n",
            "pic_b_path: target/867.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 64000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: eca\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results-eca/\n",
            "phase: test\n",
            "pic_a_path: source/920.jpg\n",
            "pic_b_path: target/870.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 64000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: eca\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results-eca/\n",
            "phase: test\n",
            "pic_a_path: source/921.jpg\n",
            "pic_b_path: target/871.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 64000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: eca\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results-eca/\n",
            "phase: test\n",
            "pic_a_path: source/922.jpg\n",
            "pic_b_path: target/873.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 64000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: eca\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results-eca/\n",
            "phase: test\n",
            "pic_a_path: source/923.jpg\n",
            "pic_b_path: target/874.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 64000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: eca\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results-eca/\n",
            "phase: test\n",
            "pic_a_path: source/924.jpg\n",
            "pic_b_path: target/875.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 64000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: eca\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results-eca/\n",
            "phase: test\n",
            "pic_a_path: source/925.jpg\n",
            "pic_b_path: target/876.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 64000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: eca\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results-eca/\n",
            "phase: test\n",
            "pic_a_path: source/926.jpg\n",
            "pic_b_path: target/877.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 64000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: eca\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results-eca/\n",
            "phase: test\n",
            "pic_a_path: source/927.jpg\n",
            "pic_b_path: target/888.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 64000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: eca\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results-eca/\n",
            "phase: test\n",
            "pic_a_path: source/930.jpg\n",
            "pic_b_path: target/889.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 64000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: eca\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results-eca/\n",
            "phase: test\n",
            "pic_a_path: source/931.jpg\n",
            "pic_b_path: target/898.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 64000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: eca\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results-eca/\n",
            "phase: test\n",
            "pic_a_path: source/932.jpg\n",
            "pic_b_path: target/900.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 64000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: eca\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results-eca/\n",
            "phase: test\n",
            "pic_a_path: source/933.jpg\n",
            "pic_b_path: target/901.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 64000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: eca\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results-eca/\n",
            "phase: test\n",
            "pic_a_path: source/934.jpg\n",
            "pic_b_path: target/902.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 64000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: eca\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results-eca/\n",
            "phase: test\n",
            "pic_a_path: source/935.jpg\n",
            "pic_b_path: target/903.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 64000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: eca\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results-eca/\n",
            "phase: test\n",
            "pic_a_path: source/936.jpg\n",
            "pic_b_path: target/904.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 64000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: eca\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results-eca/\n",
            "phase: test\n",
            "pic_a_path: source/937.jpg\n",
            "pic_b_path: target/905.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 64000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: eca\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results-eca/\n",
            "phase: test\n",
            "pic_a_path: source/940.jpg\n",
            "pic_b_path: target/907.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 64000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: eca\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results-eca/\n",
            "phase: test\n",
            "pic_a_path: source/941.jpg\n",
            "pic_b_path: target/910.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 64000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: eca\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results-eca/\n",
            "phase: test\n",
            "pic_a_path: source/942.jpg\n",
            "pic_b_path: target/911.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 64000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: eca\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results-eca/\n",
            "phase: test\n",
            "pic_a_path: source/943.jpg\n",
            "pic_b_path: target/913.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 64000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: eca\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results-eca/\n",
            "phase: test\n",
            "pic_a_path: source/944.jpg\n",
            "pic_b_path: target/914.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 64000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: eca\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results-eca/\n",
            "phase: test\n",
            "pic_a_path: source/945.jpg\n",
            "pic_b_path: target/915.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 64000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: eca\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results-eca/\n",
            "phase: test\n",
            "pic_a_path: source/946.jpg\n",
            "pic_b_path: target/916.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 64000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: eca\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results-eca/\n",
            "phase: test\n",
            "pic_a_path: source/947.jpg\n",
            "pic_b_path: target/917.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 64000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: eca\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results-eca/\n",
            "phase: test\n",
            "pic_a_path: source/950.jpg\n",
            "pic_b_path: target/928.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 64000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: eca\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results-eca/\n",
            "phase: test\n",
            "pic_a_path: source/951.jpg\n",
            "pic_b_path: target/929.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 64000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: eca\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results-eca/\n",
            "phase: test\n",
            "pic_a_path: source/952.jpg\n",
            "pic_b_path: target/938.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 64000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: eca\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results-eca/\n",
            "phase: test\n",
            "pic_a_path: source/953.jpg\n",
            "pic_b_path: target/939.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 64000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: eca\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results-eca/\n",
            "phase: test\n",
            "pic_a_path: source/954.jpg\n",
            "pic_b_path: target/948.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 64000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: eca\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results-eca/\n",
            "phase: test\n",
            "pic_a_path: source/955.jpg\n",
            "pic_b_path: target/949.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 64000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: eca\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results-eca/\n",
            "phase: test\n",
            "pic_a_path: source/956.jpg\n",
            "pic_b_path: target/958.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 64000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: eca\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results-eca/\n",
            "phase: test\n",
            "pic_a_path: source/957.jpg\n",
            "pic_b_path: target/959.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 64000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: eca\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results-eca/\n",
            "phase: test\n",
            "pic_a_path: source/968.jpg\n",
            "pic_b_path: target/960.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 64000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: eca\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results-eca/\n",
            "phase: test\n",
            "pic_a_path: source/969.jpg\n",
            "pic_b_path: target/961.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 64000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: eca\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results-eca/\n",
            "phase: test\n",
            "pic_a_path: source/978.jpg\n",
            "pic_b_path: target/962.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 64000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: eca\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results-eca/\n",
            "phase: test\n",
            "pic_a_path: source/979.jpg\n",
            "pic_b_path: target/963.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 64000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: eca\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results-eca/\n",
            "phase: test\n",
            "pic_a_path: source/980.jpg\n",
            "pic_b_path: target/964.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 64000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: eca\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results-eca/\n",
            "phase: test\n",
            "pic_a_path: source/981.jpg\n",
            "pic_b_path: target/965.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 64000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: eca\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results-eca/\n",
            "phase: test\n",
            "pic_a_path: source/982.jpg\n",
            "pic_b_path: target/966.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 64000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: eca\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results-eca/\n",
            "phase: test\n",
            "pic_a_path: source/983.jpg\n",
            "pic_b_path: target/967.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 64000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: eca\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results-eca/\n",
            "phase: test\n",
            "pic_a_path: source/984.jpg\n",
            "pic_b_path: target/970.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 64000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: eca\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results-eca/\n",
            "phase: test\n",
            "pic_a_path: source/985.jpg\n",
            "pic_b_path: target/971.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 64000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: eca\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results-eca/\n",
            "phase: test\n",
            "pic_a_path: source/986.jpg\n",
            "pic_b_path: target/972.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 64000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: eca\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results-eca/\n",
            "phase: test\n",
            "pic_a_path: source/987.jpg\n",
            "pic_b_path: target/973.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 64000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: eca\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results-eca/\n",
            "phase: test\n",
            "pic_a_path: source/990.jpg\n",
            "pic_b_path: target/974.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 64000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: eca\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results-eca/\n",
            "phase: test\n",
            "pic_a_path: source/991.jpg\n",
            "pic_b_path: target/975.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 64000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: eca\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results-eca/\n",
            "phase: test\n",
            "pic_a_path: source/992.jpg\n",
            "pic_b_path: target/976.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 64000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: eca\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results-eca/\n",
            "phase: test\n",
            "pic_a_path: source/993.jpg\n",
            "pic_b_path: target/977.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 64000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: eca\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results-eca/\n",
            "phase: test\n",
            "pic_a_path: source/994.jpg\n",
            "pic_b_path: target/988.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 64000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: eca\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results-eca/\n",
            "phase: test\n",
            "pic_a_path: source/995.jpg\n",
            "pic_b_path: target/989.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 64000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: eca\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results-eca/\n",
            "phase: test\n",
            "pic_a_path: source/996.jpg\n",
            "pic_b_path: target/998.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 64000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: eca\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results-eca/\n",
            "phase: test\n",
            "pic_a_path: source/997.jpg\n",
            "pic_b_path: target/999.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 64000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: eca\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results-eca/\n",
            "phase: test\n",
            "pic_a_path: source/SRC_01.png\n",
            "pic_b_path: target/DST_01.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 64000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: eca\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results-eca/\n",
            "phase: test\n",
            "pic_a_path: source/SRC_02.png\n",
            "pic_b_path: target/DST_02.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 64000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: checkpoints/\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: eca\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./results-eca/\n",
            "phase: test\n",
            "pic_a_path: source/SRC_03.png\n",
            "pic_b_path: target/DST_03.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: 64000\n",
            "-------------- End ----------------\n",
            "(142, 366, 4)\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " \n",
            "************ Done ! ************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import subprocess\n",
        "from tqdm import tqdm\n",
        "# same thing but flipped\n",
        "# Define paths to source and target image folders\n",
        "name = \"eca\"\n",
        "source_folder = \"target\"\n",
        "target_folder = \"source\"\n",
        "output_folder = \"results-eca\"\n",
        "epoch_number = 64000\n",
        "\n",
        "# Get lists of image files in the source and target folders\n",
        "source_files = sorted([f for f in os.listdir(source_folder) if f.endswith(('.jpg', '.jpeg', '.png'))])\n",
        "target_files = sorted([f for f in os.listdir(target_folder) if f.endswith(('.jpg', '.jpeg', '.png'))])\n",
        "\n",
        "# Ensure the number of source and target images are the same\n",
        "if len(source_files) != len(target_files):\n",
        "    print(\"Error: Number of source and target images do not match.\")\n",
        "    exit(1)\n",
        "\n",
        "# Create a progress bar\n",
        "progress_bar = tqdm(total=len(source_files), desc='Processing Images')\n",
        "\n",
        "# Iterate over each pair of source and target images\n",
        "for source_filename, target_filename in zip(source_files, target_files):\n",
        "    # Construct full paths to source and target images\n",
        "    source_img_path = os.path.join(source_folder, source_filename)\n",
        "    target_img_path = os.path.join(target_folder, target_filename)\n",
        "\n",
        "    # Construct output directory path\n",
        "    output_dir = os.path.join(output_folder, \"\")\n",
        "\n",
        "    # Ensure the output directory exists, if not create it\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Execute your Python script using subprocess\n",
        "    command = (\n",
        "    \"python test_wholeimage_swapsingle.py \"\n",
        "    \"--crop_size 224 \"\n",
        "    \"--use_mask \"\n",
        "    f\"--name {name} \" # this is the name of the checkpoint folder with model (ex. perceptual-loss-1)\n",
        "    \"--Arc_path arcface_model/arcface_checkpoint.tar \"\n",
        "    f\"--pic_a_path {source_img_path} \" # source image\n",
        "    f\"--pic_b_path {target_img_path} \" # target image\n",
        "    f\"--output_path ./{output_folder}/ \"\n",
        "    f\"--which_epoch {epoch_number} \" # this is the epoch number of the model to use (ex. 75000 )\n",
        "    \"--checkpoints_dir checkpoints/\"\n",
        "    )\n",
        "\n",
        "    # Execute the command\n",
        "    subprocess.run(command, shell=True)\n",
        "\n",
        "    # Update progress bar\n",
        "    progress_bar.update(1)\n",
        "\n",
        "# Close the progress bar\n",
        "progress_bar.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a68f3d7-c45b-470f-87b0-47d8e43cbd85",
        "id": "Mu7s7vy5Bl2A"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Images: 100%|██████████| 503/503 [1:19:58<00:00,  9.54s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from cleanfid import fid\n",
        "\n",
        "\n",
        "fake_image_path = \"results-eca\"\n",
        "\n",
        "real_image_path = \"combined_images\"\n",
        "\n",
        "fid_score = fid.compute_fid(fake_image_path, real_image_path)\n",
        "\n",
        "print(\"\\n FID Score:\", fid_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc2411d9-4a2d-4ad8-ab25-75b2b3fcdb91",
        "id": "JLtkdQE2Bl2A"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "compute FID between two folders\n",
            "Found 1006 images in the folder results-eca\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "FID results-eca : 100%|██████████| 32/32 [00:22<00:00,  1.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1006 images in the folder combined_images\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "FID combined_images : 100%|██████████| 32/32 [00:21<00:00,  1.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " FID Score: 12.33276962686574\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from cleanfid import fid\n",
        "\n",
        "fake_image_path = \"results-eca\"\n",
        "\n",
        "real_image_path = \"combined_images\"\n",
        "\n",
        "from cleanfid import fid\n",
        "clip_score = fid.compute_fid(fake_image_path, real_image_path, mode=\"clean\", model_name=\"clip_vit_b_32\")\n",
        "print(\"Clip Score:\", clip_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qADGahWKkoDe",
        "outputId": "8c63e39d-f3ff-44e5-bd69-67f968bdef85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "compute FID between two folders\n",
            "Found 1006 images in the folder results-eca\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "FID results-eca : 100%|██████████| 32/32 [00:08<00:00,  3.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1006 images in the folder combined_images\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "FID combined_images : 100%|██████████| 32/32 [00:08<00:00,  3.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clip Score: 11.691428557663784\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FID score for SimSwap baseline"
      ],
      "metadata": {
        "id": "U6gohLLhBwUl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import subprocess\n",
        "\n",
        "# Define paths to source and target image folders\n",
        "name = \"Baseline\"\n",
        "source_folder = \"source\"\n",
        "target_folder = \"target\"\n",
        "output_folder = \"results-simswap\"\n",
        "epoch_number = 55000\n",
        "\n",
        "# Get lists of image files in the source and target folders\n",
        "source_files = sorted([f for f in os.listdir(source_folder) if f.endswith(('.jpg', '.jpeg', '.png'))])\n",
        "target_files = sorted([f for f in os.listdir(target_folder) if f.endswith(('.jpg', '.jpeg', '.png'))])\n",
        "\n",
        "# Ensure the number of source and target images are the same\n",
        "if len(source_files) != len(target_files):\n",
        "    print(\"Error: Number of source and target images do not match.\")\n",
        "    exit(1)\n",
        "\n",
        "# Create a progress bar\n",
        "progress_bar = tqdm(total=len(source_files), desc='Processing Images')\n",
        "\n",
        "# Iterate over each pair of source and target images\n",
        "for source_filename, target_filename in zip(source_files, target_files):\n",
        "    # Construct full paths to source and target images\n",
        "    source_img_path = os.path.join(source_folder, source_filename)\n",
        "    target_img_path = os.path.join(target_folder, target_filename)\n",
        "\n",
        "    # Construct output directory path\n",
        "    output_dir = os.path.join(output_folder, \"\")\n",
        "\n",
        "    # Ensure the output directory exists, if not create it\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Execute your Python script using subprocess\n",
        "    command = (\n",
        "    \"python test_wholeimage_swapsingle.py \"\n",
        "    \"--crop_size 224 \"\n",
        "    \"--use_mask \"\n",
        "    f\"--name {name} \" # this is the name of the checkpoint folder with model (ex. perceptual-loss-1)\n",
        "    \"--Arc_path arcface_model/arcface_checkpoint.tar \"\n",
        "    f\"--pic_a_path {source_img_path} \" # source image\n",
        "    f\"--pic_b_path {target_img_path} \" # target image\n",
        "    f\"--output_path ./{output_folder}/ \"\n",
        "    f\"--which_epoch {epoch_number} \" # this is the epoch number of the model to use (ex. 75000 )\n",
        "    \"--checkpoints_dir checkpoints/\"\n",
        "    )\n",
        "\n",
        "    # Execute the command\n",
        "    subprocess.run(command, shell=True)\n",
        "\n",
        "    # Update progress bar\n",
        "    progress_bar.update(1)\n",
        "\n",
        "# Close the progress bar\n",
        "progress_bar.close()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iTO1S3JcBzgO",
        "outputId": "5b2acb46-8a63-4ef0-d502-6f5ed1748fa1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Processing Images:   0%|          | 2/503 [00:29<2:05:08, 14.99s/it]\n",
            "\n",
            "Processing Images:   0%|          | 1/503 [00:09<1:20:46,  9.65s/it]\u001b[A\n",
            "Processing Images:   0%|          | 2/503 [00:19<1:19:59,  9.58s/it]\u001b[A\n",
            "Processing Images:   1%|          | 3/503 [00:28<1:19:15,  9.51s/it]\u001b[A\n",
            "Processing Images:   1%|          | 4/503 [00:38<1:19:49,  9.60s/it]\u001b[A\n",
            "Processing Images:   1%|          | 5/503 [00:47<1:19:26,  9.57s/it]\u001b[A\n",
            "Processing Images:   1%|          | 6/503 [00:57<1:18:22,  9.46s/it]\u001b[A\n",
            "Processing Images:   1%|▏         | 7/503 [01:06<1:19:16,  9.59s/it]\u001b[A\n",
            "Processing Images:   2%|▏         | 8/503 [01:16<1:19:54,  9.68s/it]\u001b[A\n",
            "Processing Images:   2%|▏         | 9/503 [01:26<1:19:06,  9.61s/it]\u001b[A\n",
            "Processing Images:   2%|▏         | 10/503 [01:35<1:19:04,  9.62s/it]\u001b[A\n",
            "Processing Images:   2%|▏         | 11/503 [01:45<1:18:20,  9.55s/it]\u001b[A\n",
            "Processing Images:   2%|▏         | 12/503 [01:54<1:18:20,  9.57s/it]\u001b[A\n",
            "Processing Images:   3%|▎         | 13/503 [02:04<1:19:09,  9.69s/it]\u001b[A\n",
            "Processing Images:   3%|▎         | 14/503 [02:14<1:18:28,  9.63s/it]\u001b[A\n",
            "Processing Images:   3%|▎         | 15/503 [02:23<1:17:58,  9.59s/it]\u001b[A\n",
            "Processing Images:   3%|▎         | 16/503 [02:33<1:17:31,  9.55s/it]\u001b[A\n",
            "Processing Images:   3%|▎         | 17/503 [02:42<1:17:06,  9.52s/it]\u001b[A\n",
            "Processing Images:   4%|▎         | 18/503 [02:52<1:16:59,  9.52s/it]\u001b[A\n",
            "Processing Images:   4%|▍         | 19/503 [03:01<1:16:57,  9.54s/it]\u001b[A\n",
            "Processing Images:   4%|▍         | 20/503 [03:11<1:16:49,  9.54s/it]\u001b[A\n",
            "Processing Images:   4%|▍         | 21/503 [03:21<1:16:54,  9.57s/it]\u001b[A\n",
            "Processing Images:   4%|▍         | 22/503 [03:30<1:15:52,  9.46s/it]\u001b[A\n",
            "Processing Images:   5%|▍         | 23/503 [03:39<1:15:30,  9.44s/it]\u001b[A\n",
            "Processing Images:   5%|▍         | 24/503 [03:49<1:15:12,  9.42s/it]\u001b[A\n",
            "Processing Images:   5%|▍         | 25/503 [03:58<1:15:07,  9.43s/it]\u001b[A\n",
            "Processing Images:   5%|▌         | 26/503 [04:08<1:15:57,  9.56s/it]\u001b[A\n",
            "Processing Images:   5%|▌         | 27/503 [04:17<1:15:42,  9.54s/it]\u001b[A\n",
            "Processing Images:   6%|▌         | 28/503 [04:27<1:14:47,  9.45s/it]\u001b[A\n",
            "Processing Images:   6%|▌         | 29/503 [04:36<1:14:46,  9.47s/it]\u001b[A\n",
            "Processing Images:   6%|▌         | 30/503 [04:46<1:15:47,  9.61s/it]\u001b[A\n",
            "Processing Images:   6%|▌         | 31/503 [04:55<1:14:32,  9.48s/it]\u001b[A\n",
            "Processing Images:   6%|▋         | 32/503 [05:05<1:14:23,  9.48s/it]\u001b[A\n",
            "Processing Images:   7%|▋         | 33/503 [05:14<1:14:27,  9.51s/it]\u001b[A\n",
            "Processing Images:   7%|▋         | 34/503 [05:24<1:14:08,  9.48s/it]\u001b[A\n",
            "Processing Images:   7%|▋         | 35/503 [05:33<1:14:00,  9.49s/it]\u001b[A\n",
            "Processing Images:   7%|▋         | 36/503 [05:43<1:14:05,  9.52s/it]\u001b[A\n",
            "Processing Images:   7%|▋         | 37/503 [05:52<1:13:54,  9.52s/it]\u001b[A\n",
            "Processing Images:   8%|▊         | 38/503 [06:02<1:13:35,  9.50s/it]\u001b[A\n",
            "Processing Images:   8%|▊         | 39/503 [06:11<1:13:37,  9.52s/it]\u001b[A\n",
            "Processing Images:   8%|▊         | 40/503 [06:21<1:13:27,  9.52s/it]\u001b[A\n",
            "Processing Images:   8%|▊         | 41/503 [06:31<1:13:50,  9.59s/it]\u001b[A\n",
            "Processing Images:   8%|▊         | 42/503 [06:40<1:14:03,  9.64s/it]\u001b[A\n",
            "Processing Images:   9%|▊         | 43/503 [06:50<1:13:53,  9.64s/it]\u001b[A\n",
            "Processing Images:   9%|▊         | 44/503 [07:00<1:13:40,  9.63s/it]\u001b[A\n",
            "Processing Images:   9%|▉         | 45/503 [07:09<1:13:35,  9.64s/it]\u001b[A\n",
            "Processing Images:   9%|▉         | 46/503 [07:18<1:11:37,  9.40s/it]\u001b[A\n",
            "Processing Images:   9%|▉         | 47/503 [07:28<1:12:00,  9.48s/it]\u001b[A\n",
            "Processing Images:  10%|▉         | 48/503 [07:38<1:12:22,  9.54s/it]\u001b[A\n",
            "Processing Images:  10%|▉         | 49/503 [07:47<1:12:59,  9.65s/it]\u001b[A\n",
            "Processing Images:  10%|▉         | 50/503 [07:57<1:13:17,  9.71s/it]\u001b[A\n",
            "Processing Images:  10%|█         | 51/503 [08:07<1:13:44,  9.79s/it]\u001b[A\n",
            "Processing Images:  10%|█         | 52/503 [08:17<1:12:55,  9.70s/it]\u001b[A\n",
            "Processing Images:  11%|█         | 53/503 [08:26<1:12:28,  9.66s/it]\u001b[A\n",
            "Processing Images:  11%|█         | 54/503 [08:36<1:11:37,  9.57s/it]\u001b[A\n",
            "Processing Images:  11%|█         | 55/503 [08:45<1:11:29,  9.58s/it]\u001b[A\n",
            "Processing Images:  11%|█         | 56/503 [08:55<1:10:57,  9.52s/it]\u001b[A\n",
            "Processing Images:  11%|█▏        | 57/503 [09:04<1:10:49,  9.53s/it]\u001b[A\n",
            "Processing Images:  12%|█▏        | 58/503 [09:14<1:11:01,  9.58s/it]\u001b[A\n",
            "Processing Images:  12%|█▏        | 59/503 [09:23<1:10:58,  9.59s/it]\u001b[A\n",
            "Processing Images:  12%|█▏        | 60/503 [09:33<1:10:24,  9.54s/it]\u001b[A\n",
            "Processing Images:  12%|█▏        | 61/503 [09:42<1:10:15,  9.54s/it]\u001b[A\n",
            "Processing Images:  12%|█▏        | 62/503 [09:52<1:10:03,  9.53s/it]\u001b[A\n",
            "Processing Images:  13%|█▎        | 63/503 [10:01<1:09:47,  9.52s/it]\u001b[A\n",
            "Processing Images:  13%|█▎        | 64/503 [10:11<1:09:35,  9.51s/it]\u001b[A\n",
            "Processing Images:  13%|█▎        | 65/503 [10:20<1:09:06,  9.47s/it]\u001b[A\n",
            "Processing Images:  13%|█▎        | 66/503 [10:30<1:08:39,  9.43s/it]\u001b[A\n",
            "Processing Images:  13%|█▎        | 67/503 [10:39<1:08:22,  9.41s/it]\u001b[A\n",
            "Processing Images:  14%|█▎        | 68/503 [10:49<1:08:30,  9.45s/it]\u001b[A\n",
            "Processing Images:  14%|█▎        | 69/503 [10:58<1:09:19,  9.59s/it]\u001b[A\n",
            "Processing Images:  14%|█▍        | 70/503 [11:08<1:08:59,  9.56s/it]\u001b[A\n",
            "Processing Images:  14%|█▍        | 71/503 [11:17<1:08:28,  9.51s/it]\u001b[A\n",
            "Processing Images:  14%|█▍        | 72/503 [11:27<1:08:27,  9.53s/it]\u001b[A\n",
            "Processing Images:  15%|█▍        | 73/503 [11:36<1:08:00,  9.49s/it]\u001b[A\n",
            "Processing Images:  15%|█▍        | 74/503 [11:46<1:08:36,  9.59s/it]\u001b[A\n",
            "Processing Images:  15%|█▍        | 75/503 [11:56<1:08:17,  9.57s/it]\u001b[A\n",
            "Processing Images:  15%|█▌        | 76/503 [12:05<1:07:39,  9.51s/it]\u001b[A\n",
            "Processing Images:  15%|█▌        | 77/503 [12:15<1:07:39,  9.53s/it]\u001b[A\n",
            "Processing Images:  16%|█▌        | 78/503 [12:24<1:07:19,  9.51s/it]\u001b[A\n",
            "Processing Images:  16%|█▌        | 79/503 [12:34<1:07:19,  9.53s/it]\u001b[A\n",
            "Processing Images:  16%|█▌        | 80/503 [12:44<1:07:56,  9.64s/it]\u001b[A\n",
            "Processing Images:  16%|█▌        | 81/503 [12:53<1:07:54,  9.65s/it]\u001b[A\n",
            "Processing Images:  16%|█▋        | 82/503 [13:03<1:07:04,  9.56s/it]\u001b[A\n",
            "Processing Images:  17%|█▋        | 83/503 [13:12<1:07:05,  9.58s/it]\u001b[A\n",
            "Processing Images:  17%|█▋        | 84/503 [13:22<1:06:51,  9.57s/it]\u001b[A\n",
            "Processing Images:  17%|█▋        | 85/503 [13:31<1:06:13,  9.51s/it]\u001b[A\n",
            "Processing Images:  17%|█▋        | 86/503 [13:40<1:05:45,  9.46s/it]\u001b[A\n",
            "Processing Images:  17%|█▋        | 87/503 [13:50<1:05:26,  9.44s/it]\u001b[A\n",
            "Processing Images:  17%|█▋        | 88/503 [13:59<1:05:35,  9.48s/it]\u001b[A\n",
            "Processing Images:  18%|█▊        | 89/503 [14:09<1:05:33,  9.50s/it]\u001b[A\n",
            "Processing Images:  18%|█▊        | 90/503 [14:19<1:06:18,  9.63s/it]\u001b[A\n",
            "Processing Images:  18%|█▊        | 91/503 [14:29<1:06:07,  9.63s/it]\u001b[A\n",
            "Processing Images:  18%|█▊        | 92/503 [14:38<1:05:45,  9.60s/it]\u001b[A\n",
            "Processing Images:  18%|█▊        | 93/503 [14:48<1:05:27,  9.58s/it]\u001b[A\n",
            "Processing Images:  19%|█▊        | 94/503 [14:57<1:05:33,  9.62s/it]\u001b[A\n",
            "Processing Images:  19%|█▉        | 95/503 [15:07<1:05:41,  9.66s/it]\u001b[A\n",
            "Processing Images:  19%|█▉        | 96/503 [15:17<1:05:40,  9.68s/it]\u001b[A\n",
            "Processing Images:  19%|█▉        | 97/503 [15:27<1:06:04,  9.76s/it]\u001b[A\n",
            "Processing Images:  19%|█▉        | 98/503 [15:37<1:05:58,  9.77s/it]\u001b[A\n",
            "Processing Images:  20%|█▉        | 99/503 [15:47<1:06:23,  9.86s/it]\u001b[A\n",
            "Processing Images:  20%|█▉        | 100/503 [15:56<1:06:15,  9.86s/it]\u001b[A\n",
            "Processing Images:  20%|██        | 101/503 [16:06<1:05:23,  9.76s/it]\u001b[A\n",
            "Processing Images:  20%|██        | 102/503 [16:16<1:05:13,  9.76s/it]\u001b[A\n",
            "Processing Images:  20%|██        | 103/503 [16:25<1:04:13,  9.63s/it]\u001b[A\n",
            "Processing Images:  21%|██        | 104/503 [16:35<1:04:37,  9.72s/it]\u001b[A\n",
            "Processing Images:  21%|██        | 105/503 [16:44<1:03:57,  9.64s/it]\u001b[A\n",
            "Processing Images:  21%|██        | 106/503 [16:54<1:03:46,  9.64s/it]\u001b[A\n",
            "Processing Images:  21%|██▏       | 107/503 [17:04<1:03:27,  9.62s/it]\u001b[A\n",
            "Processing Images:  21%|██▏       | 108/503 [17:13<1:03:33,  9.65s/it]\u001b[A\n",
            "Processing Images:  22%|██▏       | 109/503 [17:23<1:03:57,  9.74s/it]\u001b[A\n",
            "Processing Images:  22%|██▏       | 110/503 [17:33<1:03:59,  9.77s/it]\u001b[A\n",
            "Processing Images:  22%|██▏       | 111/503 [17:43<1:03:43,  9.75s/it]\u001b[A\n",
            "Processing Images:  22%|██▏       | 112/503 [17:53<1:03:42,  9.78s/it]\u001b[A\n",
            "Processing Images:  22%|██▏       | 113/503 [18:02<1:03:22,  9.75s/it]\u001b[A\n",
            "Processing Images:  23%|██▎       | 114/503 [18:13<1:04:07,  9.89s/it]\u001b[A\n",
            "Processing Images:  23%|██▎       | 115/503 [18:22<1:03:28,  9.82s/it]\u001b[A\n",
            "Processing Images:  23%|██▎       | 116/503 [18:32<1:03:07,  9.79s/it]\u001b[A\n",
            "Processing Images:  23%|██▎       | 117/503 [18:42<1:02:53,  9.78s/it]\u001b[A\n",
            "Processing Images:  23%|██▎       | 118/503 [18:52<1:02:42,  9.77s/it]\u001b[A\n",
            "Processing Images:  24%|██▎       | 119/503 [19:01<1:02:32,  9.77s/it]\u001b[A\n",
            "Processing Images:  24%|██▍       | 120/503 [19:11<1:02:00,  9.71s/it]\u001b[A\n",
            "Processing Images:  24%|██▍       | 121/503 [19:20<1:01:24,  9.65s/it]\u001b[A\n",
            "Processing Images:  24%|██▍       | 122/503 [19:30<1:01:17,  9.65s/it]\u001b[A\n",
            "Processing Images:  24%|██▍       | 123/503 [19:40<1:01:15,  9.67s/it]\u001b[A\n",
            "Processing Images:  25%|██▍       | 124/503 [19:49<1:00:36,  9.60s/it]\u001b[A\n",
            "Processing Images:  25%|██▍       | 125/503 [19:58<59:55,  9.51s/it]  \u001b[A\n",
            "Processing Images:  25%|██▌       | 126/503 [20:08<1:00:23,  9.61s/it]\u001b[A\n",
            "Processing Images:  25%|██▌       | 127/503 [20:18<59:50,  9.55s/it]  \u001b[A\n",
            "Processing Images:  25%|██▌       | 128/503 [20:27<59:39,  9.54s/it]\u001b[A\n",
            "Processing Images:  26%|██▌       | 129/503 [20:37<59:07,  9.49s/it]\u001b[A\n",
            "Processing Images:  26%|██▌       | 130/503 [20:46<59:04,  9.50s/it]\u001b[A\n",
            "Processing Images:  26%|██▌       | 131/503 [20:56<59:02,  9.52s/it]\u001b[A\n",
            "Processing Images:  26%|██▌       | 132/503 [21:05<59:09,  9.57s/it]\u001b[A\n",
            "Processing Images:  26%|██▋       | 133/503 [21:15<59:10,  9.60s/it]\u001b[A\n",
            "Processing Images:  27%|██▋       | 134/503 [21:25<58:45,  9.56s/it]\u001b[A\n",
            "Processing Images:  27%|██▋       | 135/503 [21:34<58:22,  9.52s/it]\u001b[A\n",
            "Processing Images:  27%|██▋       | 136/503 [21:43<58:12,  9.52s/it]\u001b[A\n",
            "Processing Images:  27%|██▋       | 137/503 [21:53<58:00,  9.51s/it]\u001b[A\n",
            "Processing Images:  27%|██▋       | 138/503 [22:03<58:16,  9.58s/it]\u001b[A\n",
            "Processing Images:  28%|██▊       | 139/503 [22:13<58:40,  9.67s/it]\u001b[A\n",
            "Processing Images:  28%|██▊       | 140/503 [22:22<58:16,  9.63s/it]\u001b[A\n",
            "Processing Images:  28%|██▊       | 141/503 [22:32<57:44,  9.57s/it]\u001b[A\n",
            "Processing Images:  28%|██▊       | 142/503 [22:41<57:16,  9.52s/it]\u001b[A\n",
            "Processing Images:  28%|██▊       | 143/503 [22:51<57:12,  9.54s/it]\u001b[A\n",
            "Processing Images:  29%|██▊       | 144/503 [23:00<57:29,  9.61s/it]\u001b[A\n",
            "Processing Images:  29%|██▉       | 145/503 [23:09<56:08,  9.41s/it]\u001b[A\n",
            "Processing Images:  29%|██▉       | 146/503 [23:19<56:02,  9.42s/it]\u001b[A\n",
            "Processing Images:  29%|██▉       | 147/503 [23:28<56:25,  9.51s/it]\u001b[A\n",
            "Processing Images:  29%|██▉       | 148/503 [23:38<57:17,  9.68s/it]\u001b[A\n",
            "Processing Images:  30%|██▉       | 149/503 [23:48<57:14,  9.70s/it]\u001b[A\n",
            "Processing Images:  30%|██▉       | 150/503 [23:58<57:08,  9.71s/it]\u001b[A\n",
            "Processing Images:  30%|███       | 151/503 [24:08<56:41,  9.66s/it]\u001b[A\n",
            "Processing Images:  30%|███       | 152/503 [24:18<57:22,  9.81s/it]\u001b[A\n",
            "Processing Images:  30%|███       | 153/503 [24:27<57:00,  9.77s/it]\u001b[A\n",
            "Processing Images:  31%|███       | 154/503 [24:37<56:46,  9.76s/it]\u001b[A\n",
            "Processing Images:  31%|███       | 155/503 [24:47<56:40,  9.77s/it]\u001b[A\n",
            "Processing Images:  31%|███       | 156/503 [24:57<56:30,  9.77s/it]\u001b[A\n",
            "Processing Images:  31%|███       | 157/503 [25:06<55:39,  9.65s/it]\u001b[A\n",
            "Processing Images:  31%|███▏      | 158/503 [25:16<55:50,  9.71s/it]\u001b[A\n",
            "Processing Images:  32%|███▏      | 159/503 [25:25<55:18,  9.65s/it]\u001b[A\n",
            "Processing Images:  32%|███▏      | 160/503 [25:35<55:14,  9.66s/it]\u001b[A\n",
            "Processing Images:  32%|███▏      | 161/503 [25:44<54:33,  9.57s/it]\u001b[A\n",
            "Processing Images:  32%|███▏      | 162/503 [25:54<54:26,  9.58s/it]\u001b[A\n",
            "Processing Images:  32%|███▏      | 163/503 [26:03<53:42,  9.48s/it]\u001b[A\n",
            "Processing Images:  33%|███▎      | 164/503 [26:13<53:26,  9.46s/it]\u001b[A\n",
            "Processing Images:  33%|███▎      | 165/503 [26:22<53:09,  9.44s/it]\u001b[A\n",
            "Processing Images:  33%|███▎      | 166/503 [26:32<53:05,  9.45s/it]\u001b[A\n",
            "Processing Images:  33%|███▎      | 167/503 [26:41<53:13,  9.50s/it]\u001b[A\n",
            "Processing Images:  33%|███▎      | 168/503 [26:51<53:31,  9.59s/it]\u001b[A\n",
            "Processing Images:  34%|███▎      | 169/503 [27:00<52:57,  9.51s/it]\u001b[A\n",
            "Processing Images:  34%|███▍      | 170/503 [27:10<53:18,  9.61s/it]\u001b[A\n",
            "Processing Images:  34%|███▍      | 171/503 [27:20<53:58,  9.75s/it]\u001b[A\n",
            "Processing Images:  34%|███▍      | 172/503 [27:30<53:27,  9.69s/it]\u001b[A\n",
            "Processing Images:  34%|███▍      | 173/503 [27:40<53:22,  9.70s/it]\u001b[A\n",
            "Processing Images:  35%|███▍      | 174/503 [27:49<53:37,  9.78s/it]\u001b[A\n",
            "Processing Images:  35%|███▍      | 175/503 [27:59<53:28,  9.78s/it]\u001b[A\n",
            "Processing Images:  35%|███▍      | 176/503 [28:09<53:56,  9.90s/it]\u001b[A\n",
            "Processing Images:  35%|███▌      | 177/503 [28:19<53:26,  9.84s/it]\u001b[A\n",
            "Processing Images:  35%|███▌      | 178/503 [28:29<53:01,  9.79s/it]\u001b[A\n",
            "Processing Images:  36%|███▌      | 179/503 [28:38<52:40,  9.75s/it]\u001b[A\n",
            "Processing Images:  36%|███▌      | 180/503 [28:48<52:12,  9.70s/it]\u001b[A\n",
            "Processing Images:  36%|███▌      | 181/503 [28:58<51:48,  9.65s/it]\u001b[A\n",
            "Processing Images:  36%|███▌      | 182/503 [29:07<51:49,  9.69s/it]\u001b[A\n",
            "Processing Images:  36%|███▋      | 183/503 [29:17<51:28,  9.65s/it]\u001b[A\n",
            "Processing Images:  37%|███▋      | 184/503 [29:26<51:00,  9.59s/it]\u001b[A\n",
            "Processing Images:  37%|███▋      | 185/503 [29:36<51:09,  9.65s/it]\u001b[A\n",
            "Processing Images:  37%|███▋      | 186/503 [29:46<51:20,  9.72s/it]\u001b[A\n",
            "Processing Images:  37%|███▋      | 187/503 [29:56<51:32,  9.79s/it]\u001b[A\n",
            "Processing Images:  37%|███▋      | 188/503 [30:06<51:27,  9.80s/it]\u001b[A\n",
            "Processing Images:  38%|███▊      | 189/503 [30:15<50:54,  9.73s/it]\u001b[A\n",
            "Processing Images:  38%|███▊      | 190/503 [30:25<50:16,  9.64s/it]\u001b[A\n",
            "Processing Images:  38%|███▊      | 191/503 [30:35<50:46,  9.76s/it]\u001b[A\n",
            "Processing Images:  38%|███▊      | 192/503 [30:45<50:29,  9.74s/it]\u001b[A\n",
            "Processing Images:  38%|███▊      | 193/503 [30:54<50:18,  9.74s/it]\u001b[A\n",
            "Processing Images:  39%|███▊      | 194/503 [31:04<50:09,  9.74s/it]\u001b[A\n",
            "Processing Images:  39%|███▉      | 195/503 [31:14<49:50,  9.71s/it]\u001b[A\n",
            "Processing Images:  39%|███▉      | 196/503 [31:23<49:36,  9.70s/it]\u001b[A\n",
            "Processing Images:  39%|███▉      | 197/503 [31:33<49:47,  9.76s/it]\u001b[A\n",
            "Processing Images:  39%|███▉      | 198/503 [31:43<49:46,  9.79s/it]\u001b[A\n",
            "Processing Images:  40%|███▉      | 199/503 [31:53<49:37,  9.79s/it]\u001b[A\n",
            "Processing Images:  40%|███▉      | 200/503 [32:03<49:59,  9.90s/it]\u001b[A\n",
            "Processing Images:  40%|███▉      | 201/503 [32:13<50:11,  9.97s/it]\u001b[A\n",
            "Processing Images:  40%|████      | 202/503 [32:23<49:48,  9.93s/it]\u001b[A\n",
            "Processing Images:  40%|████      | 203/503 [32:33<49:28,  9.90s/it]\u001b[A\n",
            "Processing Images:  41%|████      | 204/503 [32:43<49:10,  9.87s/it]\u001b[A\n",
            "Processing Images:  41%|████      | 205/503 [32:53<49:23,  9.94s/it]\u001b[A\n",
            "Processing Images:  41%|████      | 206/503 [33:02<48:49,  9.86s/it]\u001b[A\n",
            "Processing Images:  41%|████      | 207/503 [33:12<48:28,  9.83s/it]\u001b[A\n",
            "Processing Images:  41%|████▏     | 208/503 [33:22<47:52,  9.74s/it]\u001b[A\n",
            "Processing Images:  42%|████▏     | 209/503 [33:32<47:55,  9.78s/it]\u001b[A\n",
            "Processing Images:  42%|████▏     | 210/503 [33:41<47:23,  9.71s/it]\u001b[A\n",
            "Processing Images:  42%|████▏     | 211/503 [33:51<46:48,  9.62s/it]\u001b[A\n",
            "Processing Images:  42%|████▏     | 212/503 [34:00<47:00,  9.69s/it]\u001b[A\n",
            "Processing Images:  42%|████▏     | 213/503 [34:10<47:19,  9.79s/it]\u001b[A\n",
            "Processing Images:  43%|████▎     | 214/503 [34:20<46:52,  9.73s/it]\u001b[A\n",
            "Processing Images:  43%|████▎     | 215/503 [34:30<46:27,  9.68s/it]\u001b[A\n",
            "Processing Images:  43%|████▎     | 216/503 [34:39<46:19,  9.69s/it]\u001b[A\n",
            "Processing Images:  43%|████▎     | 217/503 [34:49<46:16,  9.71s/it]\u001b[A\n",
            "Processing Images:  43%|████▎     | 218/503 [34:59<45:58,  9.68s/it]\u001b[A\n",
            "Processing Images:  44%|████▎     | 219/503 [35:08<45:38,  9.64s/it]\u001b[A\n",
            "Processing Images:  44%|████▎     | 220/503 [35:18<45:29,  9.65s/it]\u001b[A\n",
            "Processing Images:  44%|████▍     | 221/503 [35:27<45:14,  9.63s/it]\u001b[A\n",
            "Processing Images:  44%|████▍     | 222/503 [35:37<45:23,  9.69s/it]\u001b[A\n",
            "Processing Images:  44%|████▍     | 223/503 [35:47<45:23,  9.73s/it]\u001b[A\n",
            "Processing Images:  45%|████▍     | 224/503 [35:57<45:03,  9.69s/it]\u001b[A\n",
            "Processing Images:  45%|████▍     | 225/503 [36:06<44:57,  9.70s/it]\u001b[A\n",
            "Processing Images:  45%|████▍     | 226/503 [36:16<44:42,  9.68s/it]\u001b[A\n",
            "Processing Images:  45%|████▌     | 227/503 [36:26<44:15,  9.62s/it]\u001b[A\n",
            "Processing Images:  45%|████▌     | 228/503 [36:35<44:18,  9.67s/it]\u001b[A\n",
            "Processing Images:  46%|████▌     | 229/503 [36:45<44:16,  9.69s/it]\u001b[A\n",
            "Processing Images:  46%|████▌     | 230/503 [36:55<43:56,  9.66s/it]\u001b[A\n",
            "Processing Images:  46%|████▌     | 231/503 [37:05<44:04,  9.72s/it]\u001b[A\n",
            "Processing Images:  46%|████▌     | 232/503 [37:15<44:23,  9.83s/it]\u001b[A\n",
            "Processing Images:  46%|████▋     | 233/503 [37:24<43:56,  9.77s/it]\u001b[A\n",
            "Processing Images:  47%|████▋     | 234/503 [37:34<43:25,  9.68s/it]\u001b[A\n",
            "Processing Images:  47%|████▋     | 235/503 [37:44<43:49,  9.81s/it]\u001b[A\n",
            "Processing Images:  47%|████▋     | 236/503 [37:54<43:29,  9.77s/it]\u001b[A\n",
            "Processing Images:  47%|████▋     | 237/503 [38:03<43:23,  9.79s/it]\u001b[A\n",
            "Processing Images:  47%|████▋     | 238/503 [38:13<43:09,  9.77s/it]\u001b[A\n",
            "Processing Images:  48%|████▊     | 239/503 [38:23<43:02,  9.78s/it]\u001b[A\n",
            "Processing Images:  48%|████▊     | 240/503 [38:33<42:52,  9.78s/it]\u001b[A\n",
            "Processing Images:  48%|████▊     | 241/503 [38:42<42:39,  9.77s/it]\u001b[A\n",
            "Processing Images:  48%|████▊     | 242/503 [38:52<42:23,  9.75s/it]\u001b[A\n",
            "Processing Images:  48%|████▊     | 243/503 [39:02<41:51,  9.66s/it]\u001b[A\n",
            "Processing Images:  49%|████▊     | 244/503 [39:11<41:27,  9.60s/it]\u001b[A\n",
            "Processing Images:  49%|████▊     | 245/503 [39:21<41:13,  9.59s/it]\u001b[A\n",
            "Processing Images:  49%|████▉     | 246/503 [39:30<40:54,  9.55s/it]\u001b[A\n",
            "Processing Images:  49%|████▉     | 247/503 [39:40<41:22,  9.70s/it]\u001b[A\n",
            "Processing Images:  49%|████▉     | 248/503 [39:49<40:45,  9.59s/it]\u001b[A\n",
            "Processing Images:  50%|████▉     | 249/503 [39:59<40:20,  9.53s/it]\u001b[A\n",
            "Processing Images:  50%|████▉     | 250/503 [40:08<39:59,  9.49s/it]\u001b[A\n",
            "Processing Images:  50%|████▉     | 251/503 [40:18<39:54,  9.50s/it]\u001b[A\n",
            "Processing Images:  50%|█████     | 252/503 [40:27<39:55,  9.54s/it]\u001b[A\n",
            "Processing Images:  50%|█████     | 253/503 [40:37<40:00,  9.60s/it]\u001b[A\n",
            "Processing Images:  50%|█████     | 254/503 [40:47<40:14,  9.70s/it]\u001b[A\n",
            "Processing Images:  51%|█████     | 255/503 [40:57<40:12,  9.73s/it]\u001b[A\n",
            "Processing Images:  51%|█████     | 256/503 [41:07<39:59,  9.72s/it]\u001b[A\n",
            "Processing Images:  51%|█████     | 257/503 [41:16<40:06,  9.78s/it]\u001b[A\n",
            "Processing Images:  51%|█████▏    | 258/503 [41:26<39:27,  9.66s/it]\u001b[A\n",
            "Processing Images:  51%|█████▏    | 259/503 [41:35<39:16,  9.66s/it]\u001b[A\n",
            "Processing Images:  52%|█████▏    | 260/503 [41:45<39:32,  9.76s/it]\u001b[A\n",
            "Processing Images:  52%|█████▏    | 261/503 [41:55<39:14,  9.73s/it]\u001b[A\n",
            "Processing Images:  52%|█████▏    | 262/503 [42:05<39:00,  9.71s/it]\u001b[A\n",
            "Processing Images:  52%|█████▏    | 263/503 [42:14<38:46,  9.69s/it]\u001b[A\n",
            "Processing Images:  52%|█████▏    | 264/503 [42:24<38:34,  9.68s/it]\u001b[A\n",
            "Processing Images:  53%|█████▎    | 265/503 [42:34<38:12,  9.63s/it]\u001b[A\n",
            "Processing Images:  53%|█████▎    | 266/503 [42:43<38:11,  9.67s/it]\u001b[A\n",
            "Processing Images:  53%|█████▎    | 267/503 [42:53<38:12,  9.71s/it]\u001b[A\n",
            "Processing Images:  53%|█████▎    | 268/503 [43:03<37:50,  9.66s/it]\u001b[A\n",
            "Processing Images:  53%|█████▎    | 269/503 [43:12<37:27,  9.61s/it]\u001b[A\n",
            "Processing Images:  54%|█████▎    | 270/503 [43:22<37:05,  9.55s/it]\u001b[A\n",
            "Processing Images:  54%|█████▍    | 271/503 [43:31<37:06,  9.60s/it]\u001b[A\n",
            "Processing Images:  54%|█████▍    | 272/503 [43:41<36:57,  9.60s/it]\u001b[A\n",
            "Processing Images:  54%|█████▍    | 273/503 [43:51<36:56,  9.64s/it]\u001b[A\n",
            "Processing Images:  54%|█████▍    | 274/503 [44:00<36:50,  9.65s/it]\u001b[A\n",
            "Processing Images:  55%|█████▍    | 275/503 [44:10<36:44,  9.67s/it]\u001b[A\n",
            "Processing Images:  55%|█████▍    | 276/503 [44:19<36:07,  9.55s/it]\u001b[A\n",
            "Processing Images:  55%|█████▌    | 277/503 [44:29<36:04,  9.58s/it]\u001b[A\n",
            "Processing Images:  55%|█████▌    | 278/503 [44:39<35:52,  9.57s/it]\u001b[A\n",
            "Processing Images:  55%|█████▌    | 279/503 [44:48<35:36,  9.54s/it]\u001b[A\n",
            "Processing Images:  56%|█████▌    | 280/503 [44:57<35:12,  9.47s/it]\u001b[A\n",
            "Processing Images:  56%|█████▌    | 281/503 [45:07<34:57,  9.45s/it]\u001b[A\n",
            "Processing Images:  56%|█████▌    | 282/503 [45:16<34:56,  9.49s/it]\u001b[A\n",
            "Processing Images:  56%|█████▋    | 283/503 [45:26<34:41,  9.46s/it]\u001b[A\n",
            "Processing Images:  56%|█████▋    | 284/503 [45:35<34:21,  9.42s/it]\u001b[A\n",
            "Processing Images:  57%|█████▋    | 285/503 [45:45<34:47,  9.58s/it]\u001b[A\n",
            "Processing Images:  57%|█████▋    | 286/503 [45:55<34:39,  9.58s/it]\u001b[A\n",
            "Processing Images:  57%|█████▋    | 287/503 [46:04<34:35,  9.61s/it]\u001b[A\n",
            "Processing Images:  57%|█████▋    | 288/503 [46:14<34:26,  9.61s/it]\u001b[A\n",
            "Processing Images:  57%|█████▋    | 289/503 [46:23<34:05,  9.56s/it]\u001b[A\n",
            "Processing Images:  58%|█████▊    | 290/503 [46:33<33:43,  9.50s/it]\u001b[A\n",
            "Processing Images:  58%|█████▊    | 291/503 [46:43<34:00,  9.62s/it]\u001b[A\n",
            "Processing Images:  58%|█████▊    | 292/503 [46:52<33:40,  9.58s/it]\u001b[A\n",
            "Processing Images:  58%|█████▊    | 293/503 [47:01<33:18,  9.52s/it]\u001b[A\n",
            "Processing Images:  58%|█████▊    | 294/503 [47:11<32:54,  9.45s/it]\u001b[A\n",
            "Processing Images:  59%|█████▊    | 295/503 [47:21<33:21,  9.62s/it]\u001b[A\n",
            "Processing Images:  59%|█████▉    | 296/503 [47:30<33:08,  9.60s/it]\u001b[A\n",
            "Processing Images:  59%|█████▉    | 297/503 [47:40<33:10,  9.66s/it]\u001b[A\n",
            "Processing Images:  59%|█████▉    | 298/503 [47:50<32:48,  9.60s/it]\u001b[A\n",
            "Processing Images:  59%|█████▉    | 299/503 [47:59<32:35,  9.58s/it]\u001b[A\n",
            "Processing Images:  60%|█████▉    | 300/503 [48:08<32:08,  9.50s/it]\u001b[A\n",
            "Processing Images:  60%|█████▉    | 301/503 [48:18<31:54,  9.48s/it]\u001b[A\n",
            "Processing Images:  60%|██████    | 302/503 [48:27<31:44,  9.48s/it]\u001b[A\n",
            "Processing Images:  60%|██████    | 303/503 [48:37<32:00,  9.60s/it]\u001b[A\n",
            "Processing Images:  60%|██████    | 304/503 [48:47<32:01,  9.65s/it]\u001b[A\n",
            "Processing Images:  61%|██████    | 305/503 [48:56<31:24,  9.52s/it]\u001b[A\n",
            "Processing Images:  61%|██████    | 306/503 [49:06<31:18,  9.54s/it]\u001b[A\n",
            "Processing Images:  61%|██████    | 307/503 [49:15<31:05,  9.52s/it]\u001b[A\n",
            "Processing Images:  61%|██████    | 308/503 [49:25<31:12,  9.60s/it]\u001b[A\n",
            "Processing Images:  61%|██████▏   | 309/503 [49:35<31:01,  9.60s/it]\u001b[A\n",
            "Processing Images:  62%|██████▏   | 310/503 [49:44<31:01,  9.64s/it]\u001b[A\n",
            "Processing Images:  62%|██████▏   | 311/503 [49:54<30:37,  9.57s/it]\u001b[A\n",
            "Processing Images:  62%|██████▏   | 312/503 [50:03<30:15,  9.51s/it]\u001b[A\n",
            "Processing Images:  62%|██████▏   | 313/503 [50:13<30:00,  9.48s/it]\u001b[A\n",
            "Processing Images:  62%|██████▏   | 314/503 [50:22<29:58,  9.52s/it]\u001b[A\n",
            "Processing Images:  63%|██████▎   | 315/503 [50:32<29:55,  9.55s/it]\u001b[A\n",
            "Processing Images:  63%|██████▎   | 316/503 [50:42<30:03,  9.64s/it]\u001b[A\n",
            "Processing Images:  63%|██████▎   | 317/503 [50:51<30:01,  9.69s/it]\u001b[A\n",
            "Processing Images:  63%|██████▎   | 318/503 [51:01<29:57,  9.71s/it]\u001b[A\n",
            "Processing Images:  63%|██████▎   | 319/503 [51:11<29:52,  9.74s/it]\u001b[A\n",
            "Processing Images:  64%|██████▎   | 320/503 [51:21<29:41,  9.74s/it]\u001b[A\n",
            "Processing Images:  64%|██████▍   | 321/503 [51:30<29:06,  9.60s/it]\u001b[A\n",
            "Processing Images:  64%|██████▍   | 322/503 [51:40<28:53,  9.58s/it]\u001b[A\n",
            "Processing Images:  64%|██████▍   | 323/503 [51:49<28:29,  9.50s/it]\u001b[A\n",
            "Processing Images:  64%|██████▍   | 324/503 [51:58<28:12,  9.46s/it]\u001b[A\n",
            "Processing Images:  65%|██████▍   | 325/503 [52:08<28:02,  9.45s/it]\u001b[A\n",
            "Processing Images:  65%|██████▍   | 326/503 [52:17<28:01,  9.50s/it]\u001b[A\n",
            "Processing Images:  65%|██████▌   | 327/503 [52:27<27:45,  9.46s/it]\u001b[A\n",
            "Processing Images:  65%|██████▌   | 328/503 [52:37<28:01,  9.61s/it]\u001b[A\n",
            "Processing Images:  65%|██████▌   | 329/503 [52:46<28:07,  9.70s/it]\u001b[A\n",
            "Processing Images:  66%|██████▌   | 330/503 [52:56<27:39,  9.60s/it]\u001b[A\n",
            "Processing Images:  66%|██████▌   | 331/503 [53:05<27:11,  9.49s/it]\u001b[A\n",
            "Processing Images:  66%|██████▌   | 332/503 [53:14<26:53,  9.43s/it]\u001b[A\n",
            "Processing Images:  66%|██████▌   | 333/503 [53:24<26:46,  9.45s/it]\u001b[A\n",
            "Processing Images:  66%|██████▋   | 334/503 [53:33<26:30,  9.41s/it]\u001b[A\n",
            "Processing Images:  67%|██████▋   | 335/503 [53:42<26:13,  9.36s/it]\u001b[A\n",
            "Processing Images:  67%|██████▋   | 336/503 [53:52<26:18,  9.45s/it]\u001b[A\n",
            "Processing Images:  67%|██████▋   | 337/503 [54:01<26:01,  9.41s/it]\u001b[A\n",
            "Processing Images:  67%|██████▋   | 338/503 [54:12<26:30,  9.64s/it]\u001b[A\n",
            "Processing Images:  67%|██████▋   | 339/503 [54:21<26:09,  9.57s/it]\u001b[A\n",
            "Processing Images:  68%|██████▊   | 340/503 [54:31<26:02,  9.59s/it]\u001b[A\n",
            "Processing Images:  68%|██████▊   | 341/503 [54:40<25:54,  9.60s/it]\u001b[A\n",
            "Processing Images:  68%|██████▊   | 342/503 [54:50<25:46,  9.60s/it]\u001b[A\n",
            "Processing Images:  68%|██████▊   | 343/503 [55:00<25:43,  9.65s/it]\u001b[A\n",
            "Processing Images:  68%|██████▊   | 344/503 [55:09<25:29,  9.62s/it]\u001b[A\n",
            "Processing Images:  69%|██████▊   | 345/503 [55:19<25:17,  9.61s/it]\u001b[A\n",
            "Processing Images:  69%|██████▉   | 346/503 [55:28<25:07,  9.60s/it]\u001b[A\n",
            "Processing Images:  69%|██████▉   | 347/503 [55:38<24:50,  9.55s/it]\u001b[A\n",
            "Processing Images:  69%|██████▉   | 348/503 [55:47<24:48,  9.60s/it]\u001b[A\n",
            "Processing Images:  69%|██████▉   | 349/503 [55:57<24:50,  9.68s/it]\u001b[A\n",
            "Processing Images:  70%|██████▉   | 350/503 [56:07<24:30,  9.61s/it]\u001b[A\n",
            "Processing Images:  70%|██████▉   | 351/503 [56:16<24:15,  9.58s/it]\u001b[A\n",
            "Processing Images:  70%|██████▉   | 352/503 [56:26<24:07,  9.58s/it]\u001b[A\n",
            "Processing Images:  70%|███████   | 353/503 [56:35<23:57,  9.58s/it]\u001b[A\n",
            "Processing Images:  70%|███████   | 354/503 [56:45<23:57,  9.65s/it]\u001b[A\n",
            "Processing Images:  71%|███████   | 355/503 [56:55<23:39,  9.59s/it]\u001b[A\n",
            "Processing Images:  71%|███████   | 356/503 [57:05<23:39,  9.66s/it]\u001b[A\n",
            "Processing Images:  71%|███████   | 357/503 [57:14<23:11,  9.53s/it]\u001b[A\n",
            "Processing Images:  71%|███████   | 358/503 [57:23<22:58,  9.51s/it]\u001b[A\n",
            "Processing Images:  71%|███████▏  | 359/503 [57:33<22:47,  9.49s/it]\u001b[A\n",
            "Processing Images:  72%|███████▏  | 360/503 [57:42<22:44,  9.54s/it]\u001b[A\n",
            "Processing Images:  72%|███████▏  | 361/503 [57:52<22:42,  9.59s/it]\u001b[A\n",
            "Processing Images:  72%|███████▏  | 362/503 [58:02<22:27,  9.56s/it]\u001b[A\n",
            "Processing Images:  72%|███████▏  | 363/503 [58:12<22:44,  9.75s/it]\u001b[A\n",
            "Processing Images:  72%|███████▏  | 364/503 [58:22<22:40,  9.79s/it]\u001b[A\n",
            "Processing Images:  73%|███████▎  | 365/503 [58:32<22:41,  9.86s/it]\u001b[A\n",
            "Processing Images:  73%|███████▎  | 366/503 [58:42<22:40,  9.93s/it]\u001b[A\n",
            "Processing Images:  73%|███████▎  | 367/503 [58:51<22:11,  9.79s/it]\u001b[A\n",
            "Processing Images:  73%|███████▎  | 368/503 [59:01<21:54,  9.74s/it]\u001b[A\n",
            "Processing Images:  73%|███████▎  | 369/503 [59:11<21:44,  9.73s/it]\u001b[A\n",
            "Processing Images:  74%|███████▎  | 370/503 [59:20<21:21,  9.64s/it]\u001b[A\n",
            "Processing Images:  74%|███████▍  | 371/503 [59:30<21:12,  9.64s/it]\u001b[A\n",
            "Processing Images:  74%|███████▍  | 372/503 [59:39<20:58,  9.61s/it]\u001b[A\n",
            "Processing Images:  74%|███████▍  | 373/503 [59:49<21:03,  9.72s/it]\u001b[A\n",
            "Processing Images:  74%|███████▍  | 374/503 [59:59<20:47,  9.67s/it]\u001b[A\n",
            "Processing Images:  75%|███████▍  | 375/503 [1:00:08<20:37,  9.67s/it]\u001b[A\n",
            "Processing Images:  75%|███████▍  | 376/503 [1:00:18<20:38,  9.75s/it]\u001b[A\n",
            "Processing Images:  75%|███████▍  | 377/503 [1:00:27<20:08,  9.59s/it]\u001b[A\n",
            "Processing Images:  75%|███████▌  | 378/503 [1:00:38<20:20,  9.76s/it]\u001b[A\n",
            "Processing Images:  75%|███████▌  | 379/503 [1:00:47<20:05,  9.72s/it]\u001b[A\n",
            "Processing Images:  76%|███████▌  | 380/503 [1:00:57<19:55,  9.72s/it]\u001b[A\n",
            "Processing Images:  76%|███████▌  | 381/503 [1:01:07<19:49,  9.75s/it]\u001b[A\n",
            "Processing Images:  76%|███████▌  | 382/503 [1:01:17<19:46,  9.81s/it]\u001b[A\n",
            "Processing Images:  76%|███████▌  | 383/503 [1:01:26<19:31,  9.77s/it]\u001b[A\n",
            "Processing Images:  76%|███████▋  | 384/503 [1:01:36<19:30,  9.84s/it]\u001b[A\n",
            "Processing Images:  77%|███████▋  | 385/503 [1:01:47<19:32,  9.94s/it]\u001b[A\n",
            "Processing Images:  77%|███████▋  | 386/503 [1:01:56<19:15,  9.88s/it]\u001b[A\n",
            "Processing Images:  77%|███████▋  | 387/503 [1:02:06<19:09,  9.91s/it]\u001b[A\n",
            "Processing Images:  77%|███████▋  | 388/503 [1:02:17<19:12, 10.02s/it]\u001b[A\n",
            "Processing Images:  77%|███████▋  | 389/503 [1:02:26<18:51,  9.93s/it]\u001b[A\n",
            "Processing Images:  78%|███████▊  | 390/503 [1:02:36<18:41,  9.92s/it]\u001b[A\n",
            "Processing Images:  78%|███████▊  | 391/503 [1:02:46<18:33,  9.94s/it]\u001b[A\n",
            "Processing Images:  78%|███████▊  | 392/503 [1:02:56<18:14,  9.86s/it]\u001b[A\n",
            "Processing Images:  78%|███████▊  | 393/503 [1:03:06<18:04,  9.86s/it]\u001b[A\n",
            "Processing Images:  78%|███████▊  | 394/503 [1:03:16<17:54,  9.86s/it]\u001b[A\n",
            "Processing Images:  79%|███████▊  | 395/503 [1:03:25<17:41,  9.83s/it]\u001b[A\n",
            "Processing Images:  79%|███████▊  | 396/503 [1:03:35<17:26,  9.78s/it]\u001b[A\n",
            "Processing Images:  79%|███████▉  | 397/503 [1:03:45<17:15,  9.77s/it]\u001b[A\n",
            "Processing Images:  79%|███████▉  | 398/503 [1:03:54<16:58,  9.70s/it]\u001b[A\n",
            "Processing Images:  79%|███████▉  | 399/503 [1:04:04<16:46,  9.68s/it]\u001b[A\n",
            "Processing Images:  80%|███████▉  | 400/503 [1:04:14<16:35,  9.67s/it]\u001b[A\n",
            "Processing Images:  80%|███████▉  | 401/503 [1:04:24<16:36,  9.77s/it]\u001b[A\n",
            "Processing Images:  80%|███████▉  | 402/503 [1:04:33<16:27,  9.78s/it]\u001b[A\n",
            "Processing Images:  80%|████████  | 403/503 [1:04:43<16:17,  9.78s/it]\u001b[A\n",
            "Processing Images:  80%|████████  | 404/503 [1:04:53<15:55,  9.66s/it]\u001b[A\n",
            "Processing Images:  81%|████████  | 405/503 [1:05:02<15:49,  9.69s/it]\u001b[A\n",
            "Processing Images:  81%|████████  | 406/503 [1:05:12<15:36,  9.65s/it]\u001b[A\n",
            "Processing Images:  81%|████████  | 407/503 [1:05:21<15:20,  9.59s/it]\u001b[A\n",
            "Processing Images:  81%|████████  | 408/503 [1:05:31<15:26,  9.76s/it]\u001b[A\n",
            "Processing Images:  81%|████████▏ | 409/503 [1:05:41<15:07,  9.65s/it]\u001b[A\n",
            "Processing Images:  82%|████████▏ | 410/503 [1:05:51<15:02,  9.70s/it]\u001b[A\n",
            "Processing Images:  82%|████████▏ | 411/503 [1:06:00<14:47,  9.65s/it]\u001b[A\n",
            "Processing Images:  82%|████████▏ | 412/503 [1:06:10<14:41,  9.69s/it]\u001b[A\n",
            "Processing Images:  82%|████████▏ | 413/503 [1:06:20<14:30,  9.68s/it]\u001b[A\n",
            "Processing Images:  82%|████████▏ | 414/503 [1:06:30<14:30,  9.78s/it]\u001b[A\n",
            "Processing Images:  83%|████████▎ | 415/503 [1:06:39<14:21,  9.79s/it]\u001b[A\n",
            "Processing Images:  83%|████████▎ | 416/503 [1:06:49<14:11,  9.79s/it]\u001b[A\n",
            "Processing Images:  83%|████████▎ | 417/503 [1:06:59<13:53,  9.69s/it]\u001b[A\n",
            "Processing Images:  83%|████████▎ | 418/503 [1:07:08<13:35,  9.59s/it]\u001b[A\n",
            "Processing Images:  83%|████████▎ | 419/503 [1:07:17<13:20,  9.53s/it]\u001b[A\n",
            "Processing Images:  83%|████████▎ | 420/503 [1:07:27<13:14,  9.57s/it]\u001b[A\n",
            "Processing Images:  84%|████████▎ | 421/503 [1:07:37<13:03,  9.55s/it]\u001b[A\n",
            "Processing Images:  84%|████████▍ | 422/503 [1:07:46<12:50,  9.51s/it]\u001b[A\n",
            "Processing Images:  84%|████████▍ | 423/503 [1:07:56<12:42,  9.53s/it]\u001b[A\n",
            "Processing Images:  84%|████████▍ | 424/503 [1:08:05<12:30,  9.50s/it]\u001b[A\n",
            "Processing Images:  84%|████████▍ | 425/503 [1:08:15<12:23,  9.53s/it]\u001b[A\n",
            "Processing Images:  85%|████████▍ | 426/503 [1:08:24<12:15,  9.55s/it]\u001b[A\n",
            "Processing Images:  85%|████████▍ | 427/503 [1:08:34<12:05,  9.54s/it]\u001b[A\n",
            "Processing Images:  85%|████████▌ | 428/503 [1:08:43<11:51,  9.49s/it]\u001b[A\n",
            "Processing Images:  85%|████████▌ | 429/503 [1:08:53<11:45,  9.53s/it]\u001b[A\n",
            "Processing Images:  85%|████████▌ | 430/503 [1:09:03<11:42,  9.62s/it]\u001b[A\n",
            "Processing Images:  86%|████████▌ | 431/503 [1:09:13<11:39,  9.72s/it]\u001b[A\n",
            "Processing Images:  86%|████████▌ | 432/503 [1:09:22<11:30,  9.73s/it]\u001b[A\n",
            "Processing Images:  86%|████████▌ | 433/503 [1:09:32<11:22,  9.75s/it]\u001b[A\n",
            "Processing Images:  86%|████████▋ | 434/503 [1:09:42<11:13,  9.76s/it]\u001b[A\n",
            "Processing Images:  86%|████████▋ | 435/503 [1:09:51<11:01,  9.73s/it]\u001b[A\n",
            "Processing Images:  87%|████████▋ | 436/503 [1:10:01<10:54,  9.77s/it]\u001b[A\n",
            "Processing Images:  87%|████████▋ | 437/503 [1:10:11<10:44,  9.76s/it]\u001b[A\n",
            "Processing Images:  87%|████████▋ | 438/503 [1:10:21<10:39,  9.84s/it]\u001b[A\n",
            "Processing Images:  87%|████████▋ | 439/503 [1:10:30<10:20,  9.70s/it]\u001b[A\n",
            "Processing Images:  87%|████████▋ | 440/503 [1:10:40<10:14,  9.76s/it]\u001b[A\n",
            "Processing Images:  88%|████████▊ | 441/503 [1:10:50<10:03,  9.74s/it]\u001b[A\n",
            "Processing Images:  88%|████████▊ | 442/503 [1:11:00<10:00,  9.84s/it]\u001b[A\n",
            "Processing Images:  88%|████████▊ | 443/503 [1:11:10<09:46,  9.77s/it]\u001b[A\n",
            "Processing Images:  88%|████████▊ | 444/503 [1:11:19<09:32,  9.70s/it]\u001b[A\n",
            "Processing Images:  88%|████████▊ | 445/503 [1:11:29<09:20,  9.66s/it]\u001b[A\n",
            "Processing Images:  89%|████████▊ | 446/503 [1:11:39<09:10,  9.67s/it]\u001b[A\n",
            "Processing Images:  89%|████████▉ | 447/503 [1:11:48<09:02,  9.69s/it]\u001b[A\n",
            "Processing Images:  89%|████████▉ | 448/503 [1:11:58<08:51,  9.67s/it]\u001b[A\n",
            "Processing Images:  89%|████████▉ | 449/503 [1:12:08<08:43,  9.69s/it]\u001b[A\n",
            "Processing Images:  89%|████████▉ | 450/503 [1:12:18<08:38,  9.78s/it]\u001b[A\n",
            "Processing Images:  90%|████████▉ | 451/503 [1:12:27<08:25,  9.73s/it]\u001b[A\n",
            "Processing Images:  90%|████████▉ | 452/503 [1:12:37<08:20,  9.81s/it]\u001b[A\n",
            "Processing Images:  90%|█████████ | 453/503 [1:12:47<08:06,  9.74s/it]\u001b[A\n",
            "Processing Images:  90%|█████████ | 454/503 [1:12:56<07:53,  9.67s/it]\u001b[A\n",
            "Processing Images:  90%|█████████ | 455/503 [1:13:06<07:47,  9.73s/it]\u001b[A\n",
            "Processing Images:  91%|█████████ | 456/503 [1:13:16<07:35,  9.68s/it]\u001b[A\n",
            "Processing Images:  91%|█████████ | 457/503 [1:13:26<07:32,  9.84s/it]\u001b[A\n",
            "Processing Images:  91%|█████████ | 458/503 [1:13:36<07:21,  9.82s/it]\u001b[A\n",
            "Processing Images:  91%|█████████▏| 459/503 [1:13:45<07:08,  9.75s/it]\u001b[A\n",
            "Processing Images:  91%|█████████▏| 460/503 [1:13:55<06:57,  9.70s/it]\u001b[A\n",
            "Processing Images:  92%|█████████▏| 461/503 [1:14:05<06:50,  9.78s/it]\u001b[A\n",
            "Processing Images:  92%|█████████▏| 462/503 [1:14:14<06:37,  9.70s/it]\u001b[A\n",
            "Processing Images:  92%|█████████▏| 463/503 [1:14:24<06:31,  9.78s/it]\u001b[A\n",
            "Processing Images:  92%|█████████▏| 464/503 [1:14:34<06:25,  9.87s/it]\u001b[A\n",
            "Processing Images:  92%|█████████▏| 465/503 [1:14:45<06:18,  9.97s/it]\u001b[A\n",
            "Processing Images:  93%|█████████▎| 466/503 [1:14:55<06:07,  9.95s/it]\u001b[A\n",
            "Processing Images:  93%|█████████▎| 467/503 [1:15:04<05:57,  9.92s/it]\u001b[A\n",
            "Processing Images:  93%|█████████▎| 468/503 [1:15:14<05:46,  9.91s/it]\u001b[A\n",
            "Processing Images:  93%|█████████▎| 469/503 [1:15:24<05:33,  9.81s/it]\u001b[A\n",
            "Processing Images:  93%|█████████▎| 470/503 [1:15:34<05:25,  9.86s/it]\u001b[A\n",
            "Processing Images:  94%|█████████▎| 471/503 [1:15:44<05:15,  9.85s/it]\u001b[A\n",
            "Processing Images:  94%|█████████▍| 472/503 [1:15:53<05:03,  9.81s/it]\u001b[A\n",
            "Processing Images:  94%|█████████▍| 473/503 [1:16:04<04:57,  9.93s/it]\u001b[A\n",
            "Processing Images:  94%|█████████▍| 474/503 [1:16:13<04:46,  9.89s/it]\u001b[A\n",
            "Processing Images:  94%|█████████▍| 475/503 [1:16:23<04:36,  9.87s/it]\u001b[A\n",
            "Processing Images:  95%|█████████▍| 476/503 [1:16:33<04:27,  9.89s/it]\u001b[A\n",
            "Processing Images:  95%|█████████▍| 477/503 [1:16:43<04:16,  9.88s/it]\u001b[A\n",
            "Processing Images:  95%|█████████▌| 478/503 [1:16:53<04:04,  9.78s/it]\u001b[A\n",
            "Processing Images:  95%|█████████▌| 479/503 [1:17:02<03:54,  9.76s/it]\u001b[A\n",
            "Processing Images:  95%|█████████▌| 480/503 [1:17:13<03:47,  9.89s/it]\u001b[A\n",
            "Processing Images:  96%|█████████▌| 481/503 [1:17:22<03:37,  9.88s/it]\u001b[A\n",
            "Processing Images:  96%|█████████▌| 482/503 [1:17:32<03:26,  9.85s/it]\u001b[A\n",
            "Processing Images:  96%|█████████▌| 483/503 [1:17:42<03:16,  9.84s/it]\u001b[A\n",
            "Processing Images:  96%|█████████▌| 484/503 [1:17:52<03:07,  9.86s/it]\u001b[A\n",
            "Processing Images:  96%|█████████▋| 485/503 [1:18:02<02:56,  9.81s/it]\u001b[A\n",
            "Processing Images:  97%|█████████▋| 486/503 [1:18:12<02:47,  9.86s/it]\u001b[A\n",
            "Processing Images:  97%|█████████▋| 487/503 [1:18:21<02:37,  9.85s/it]\u001b[A\n",
            "Processing Images:  97%|█████████▋| 488/503 [1:18:31<02:27,  9.82s/it]\u001b[A\n",
            "Processing Images:  97%|█████████▋| 489/503 [1:18:41<02:16,  9.78s/it]\u001b[A\n",
            "Processing Images:  97%|█████████▋| 490/503 [1:18:51<02:08,  9.87s/it]\u001b[A\n",
            "Processing Images:  98%|█████████▊| 491/503 [1:19:01<01:58,  9.87s/it]\u001b[A\n",
            "Processing Images:  98%|█████████▊| 492/503 [1:19:10<01:47,  9.76s/it]\u001b[A\n",
            "Processing Images:  98%|█████████▊| 493/503 [1:19:20<01:36,  9.64s/it]\u001b[A\n",
            "Processing Images:  98%|█████████▊| 494/503 [1:19:29<01:27,  9.67s/it]\u001b[A\n",
            "Processing Images:  98%|█████████▊| 495/503 [1:19:39<01:17,  9.74s/it]\u001b[A\n",
            "Processing Images:  99%|█████████▊| 496/503 [1:19:49<01:08,  9.72s/it]\u001b[A\n",
            "Processing Images:  99%|█████████▉| 497/503 [1:19:59<00:58,  9.71s/it]\u001b[A\n",
            "Processing Images:  99%|█████████▉| 498/503 [1:20:08<00:48,  9.72s/it]\u001b[A\n",
            "Processing Images:  99%|█████████▉| 499/503 [1:20:18<00:38,  9.71s/it]\u001b[A\n",
            "Processing Images:  99%|█████████▉| 500/503 [1:20:28<00:29,  9.79s/it]\u001b[A\n",
            "Processing Images: 100%|█████████▉| 501/503 [1:20:38<00:19,  9.76s/it]\u001b[A\n",
            "Processing Images: 100%|█████████▉| 502/503 [1:20:47<00:09,  9.73s/it]\u001b[A\n",
            "Processing Images: 100%|██████████| 503/503 [1:20:57<00:00,  9.66s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import subprocess\n",
        "from tqdm import tqdm\n",
        "# same thing but flipped\n",
        "# Define paths to source and target image folders\n",
        "name = \"Baseline\"\n",
        "source_folder = \"target\"\n",
        "target_folder = \"source\"\n",
        "output_folder = \"results-simswap\"\n",
        "epoch_number = 55000\n",
        "\n",
        "# Get lists of image files in the source and target folders\n",
        "source_files = sorted([f for f in os.listdir(source_folder) if f.endswith(('.jpg', '.jpeg', '.png'))])\n",
        "target_files = sorted([f for f in os.listdir(target_folder) if f.endswith(('.jpg', '.jpeg', '.png'))])\n",
        "\n",
        "# Ensure the number of source and target images are the same\n",
        "if len(source_files) != len(target_files):\n",
        "    print(\"Error: Number of source and target images do not match.\")\n",
        "    exit(1)\n",
        "\n",
        "# Create a progress bar\n",
        "progress_bar = tqdm(total=len(source_files), desc='Processing Images')\n",
        "\n",
        "# Iterate over each pair of source and target images\n",
        "for source_filename, target_filename in zip(source_files, target_files):\n",
        "    # Construct full paths to source and target images\n",
        "    source_img_path = os.path.join(source_folder, source_filename)\n",
        "    target_img_path = os.path.join(target_folder, target_filename)\n",
        "\n",
        "    # Construct output directory path\n",
        "    output_dir = os.path.join(output_folder, \"\")\n",
        "\n",
        "    # Ensure the output directory exists, if not create it\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Execute your Python script using subprocess\n",
        "    command = (\n",
        "    \"python test_wholeimage_swapsingle.py \"\n",
        "    \"--crop_size 224 \"\n",
        "    \"--use_mask \"\n",
        "    f\"--name {name} \" # this is the name of the checkpoint folder with model (ex. perceptual-loss-1)\n",
        "    \"--Arc_path arcface_model/arcface_checkpoint.tar \"\n",
        "    f\"--pic_a_path {source_img_path} \" # source image\n",
        "    f\"--pic_b_path {target_img_path} \" # target image\n",
        "    f\"--output_path ./{output_folder}/ \"\n",
        "    f\"--which_epoch {epoch_number} \" # this is the epoch number of the model to use (ex. 75000 )\n",
        "    \"--checkpoints_dir checkpoints/\"\n",
        "    )\n",
        "\n",
        "    # Execute the command\n",
        "    subprocess.run(command, shell=True)\n",
        "\n",
        "    # Update progress bar\n",
        "    progress_bar.update(1)\n",
        "\n",
        "# Close the progress bar\n",
        "progress_bar.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81gWx_51CGfd",
        "outputId": "926c3e51-6dc7-4719-9978-9857573d33cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Images: 100%|██████████| 503/503 [1:19:49<00:00,  9.52s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from cleanfid import fid\n",
        "\n",
        "\n",
        "fake_image_path = \"results-simswap\"\n",
        "\n",
        "real_image_path = \"combined_images\"\n",
        "\n",
        "fid_score = fid.compute_fid(fake_image_path, real_image_path)\n",
        "\n",
        "print(\"\\n FID Score:\", fid_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uvl4LPRuCMrU",
        "outputId": "3d478865-3802-446e-da66-94aeea931d72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "compute FID between two folders\n",
            "Found 1006 images in the folder results-simswap\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "FID results-simswap : 100%|██████████| 32/32 [00:22<00:00,  1.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1006 images in the folder combined_images\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "FID combined_images : 100%|██████████| 32/32 [00:21<00:00,  1.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " FID Score: 11.654060293443479\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from cleanfid import fid\n",
        "\n",
        "fake_image_path = \"results-simswap\"\n",
        "\n",
        "real_image_path = \"combined_images\"\n",
        "\n",
        "from cleanfid import fid\n",
        "clip_score = fid.compute_fid(fake_image_path, real_image_path, mode=\"clean\", model_name=\"clip_vit_b_32\")\n",
        "print(\"Clip Score:\", clip_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1PoGnHh2kVw1",
        "outputId": "cf8f4615-fd8d-4784-b397-b61f42efe64f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "compute FID between two folders\n",
            "Found 1006 images in the folder results-simswap\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "FID results-simswap : 100%|██████████| 32/32 [00:08<00:00,  3.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1006 images in the folder combined_images\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "FID combined_images : 100%|██████████| 32/32 [00:08<00:00,  3.75it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FID score for SSIMLoss"
      ],
      "metadata": {
        "id": "3uWamvRuz6JR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gdown.download_folder(\"https://drive.google.com/drive/u/1/folders/1DQtf1Re89D2hSsFEjasudsc0_R929VrT\", quiet=True)"
      ],
      "metadata": {
        "id": "e79FRhld0f3-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca5bea80-45c8-45f0-e625-0d079bf518d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/idl-project/SimSwap/ssim-loss/28000_net_D.pth',\n",
              " '/content/idl-project/SimSwap/ssim-loss/28000_optim_D.pth',\n",
              " '/content/idl-project/SimSwap/ssim-loss/30000_net_D.pth',\n",
              " '/content/idl-project/SimSwap/ssim-loss/30000_net_G.pth',\n",
              " '/content/idl-project/SimSwap/ssim-loss/30000_optim_D.pth',\n",
              " '/content/idl-project/SimSwap/ssim-loss/30000_optim_G.pth']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import subprocess\n",
        "\n",
        "# Define paths to source and target image folders\n",
        "name = \"ssim-loss\"\n",
        "source_folder = \"source\"\n",
        "target_folder = \"target\"\n",
        "output_folder = \"results-ssim\"\n",
        "epoch_number = 30000\n",
        "\n",
        "# Get lists of image files in the source and target folders\n",
        "source_files = sorted([f for f in os.listdir(source_folder) if f.endswith(('.jpg', '.jpeg', '.png'))])\n",
        "target_files = sorted([f for f in os.listdir(target_folder) if f.endswith(('.jpg', '.jpeg', '.png'))])\n",
        "\n",
        "# Ensure the number of source and target images are the same\n",
        "if len(source_files) != len(target_files):\n",
        "    print(\"Error: Number of source and target images do not match.\")\n",
        "    exit(1)\n",
        "\n",
        "# Create a progress bar\n",
        "progress_bar = tqdm(total=len(source_files), desc='Processing Images')\n",
        "\n",
        "# Iterate over each pair of source and target images\n",
        "for source_filename, target_filename in zip(source_files, target_files):\n",
        "    # Construct full paths to source and target images\n",
        "    source_img_path = os.path.join(source_folder, source_filename)\n",
        "    target_img_path = os.path.join(target_folder, target_filename)\n",
        "\n",
        "    # Construct output directory path\n",
        "    output_dir = os.path.join(output_folder, \"\")\n",
        "\n",
        "    # Ensure the output directory exists, if not create it\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Execute your Python script using subprocess\n",
        "    command = (\n",
        "    \"python test_wholeimage_swapsingle.py \"\n",
        "    \"--crop_size 224 \"\n",
        "    \"--use_mask \"\n",
        "    f\"--name {name} \" # this is the name of the checkpoint folder with model (ex. perceptual-loss-1)\n",
        "    \"--Arc_path arcface_model/arcface_checkpoint.tar \"\n",
        "    f\"--pic_a_path {source_img_path} \" # source image\n",
        "    f\"--pic_b_path {target_img_path} \" # target image\n",
        "    f\"--output_path ./{output_folder}/ \"\n",
        "    f\"--which_epoch {epoch_number} \" # this is the epoch number of the model to use (ex. 75000 )\n",
        "    \"--checkpoints_dir checkpoints/\"\n",
        "    )\n",
        "\n",
        "    # Execute the command\n",
        "    subprocess.run(command, shell=True)\n",
        "\n",
        "    # Update progress bar\n",
        "    progress_bar.update(1)\n",
        "\n",
        "# Close the progress bar\n",
        "progress_bar.close()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "liGgE22Xz8iO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e1d3954-247f-4ee9-9376-ca6fdaaebeb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Images: 100%|██████████| 503/503 [1:19:03<00:00,  9.43s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import subprocess\n",
        "\n",
        "# Define paths to source and target image folders\n",
        "name = \"ssim-loss\"\n",
        "source_folder = \"target\"\n",
        "target_folder = \"source\"\n",
        "output_folder = \"results-ssim\"\n",
        "epoch_number = 30000\n",
        "\n",
        "# Get lists of image files in the source and target folders\n",
        "source_files = sorted([f for f in os.listdir(source_folder) if f.endswith(('.jpg', '.jpeg', '.png'))])\n",
        "target_files = sorted([f for f in os.listdir(target_folder) if f.endswith(('.jpg', '.jpeg', '.png'))])\n",
        "\n",
        "# Ensure the number of source and target images are the same\n",
        "if len(source_files) != len(target_files):\n",
        "    print(\"Error: Number of source and target images do not match.\")\n",
        "    exit(1)\n",
        "\n",
        "# Create a progress bar\n",
        "progress_bar = tqdm(total=len(source_files), desc='Processing Images')\n",
        "\n",
        "# Iterate over each pair of source and target images\n",
        "for source_filename, target_filename in zip(source_files, target_files):\n",
        "    # Construct full paths to source and target images\n",
        "    source_img_path = os.path.join(source_folder, source_filename)\n",
        "    target_img_path = os.path.join(target_folder, target_filename)\n",
        "\n",
        "    # Construct output directory path\n",
        "    output_dir = os.path.join(output_folder, \"\")\n",
        "\n",
        "    # Ensure the output directory exists, if not create it\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Execute your Python script using subprocess\n",
        "    command = (\n",
        "    \"python test_wholeimage_swapsingle.py \"\n",
        "    \"--crop_size 224 \"\n",
        "    \"--use_mask \"\n",
        "    f\"--name {name} \" # this is the name of the checkpoint folder with model (ex. perceptual-loss-1)\n",
        "    \"--Arc_path arcface_model/arcface_checkpoint.tar \"\n",
        "    f\"--pic_a_path {source_img_path} \" # source image\n",
        "    f\"--pic_b_path {target_img_path} \" # target image\n",
        "    f\"--output_path ./{output_folder}/ \"\n",
        "    f\"--which_epoch {epoch_number} \" # this is the epoch number of the model to use (ex. 75000 )\n",
        "    \"--checkpoints_dir checkpoints/\"\n",
        "    )\n",
        "\n",
        "    # Execute the command\n",
        "    subprocess.run(command, shell=True)\n",
        "\n",
        "    # Update progress bar\n",
        "    progress_bar.update(1)\n",
        "\n",
        "# Close the progress bar\n",
        "progress_bar.close()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jgm2gU8h-mwG",
        "outputId": "491cff6c-07e0-4cbe-c273-7f51d8c96dba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Images: 100%|██████████| 503/503 [1:18:13<00:00,  9.33s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from cleanfid import fid\n",
        "\n",
        "fake_image_path = \"results-ssim\"\n",
        "\n",
        "real_image_path = \"combined_images\"\n",
        "\n",
        "fid_score = fid.compute_fid(fake_image_path, real_image_path)\n",
        "\n",
        "print(\"\\n FID Score:\", fid_score)"
      ],
      "metadata": {
        "id": "7QWRkeE8-p6d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1faa2f84-53e9-4bfb-81d2-2eb9b62e2d87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "compute FID between two folders\n",
            "Found 1006 images in the folder results-ssim\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "FID results-ssim : 100%|██████████| 32/32 [00:22<00:00,  1.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1006 images in the folder combined_images\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "FID combined_images : 100%|██████████| 32/32 [00:21<00:00,  1.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " FID Score: 14.778232381117562\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CLIP-FID scores"
      ],
      "metadata": {
        "id": "XphyPP88qpqz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install git+https://github.com/openai/CLIP.git --user"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 775
        },
        "id": "knoNrgJKjtq-",
        "outputId": "97265bf4-0706-4478-8f6f-997781047d38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/openai/CLIP.git\n",
            "  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-eatz6ouw\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-req-build-eatz6ouw\n",
            "  Resolved https://github.com/openai/CLIP.git to commit a1d071733d7111c9c014f024669f959182114e33\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ftfy (from clip==1.0)\n",
            "  Using cached ftfy-6.2.0-py3-none-any.whl (54 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (4.66.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (2.1.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (0.16.0+cu121)\n",
            "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from ftfy->clip==1.0) (0.2.13)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (2.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->clip==1.0) (1.23.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision->clip==1.0) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->clip==1.0) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->clip==1.0) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->clip==1.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->clip==1.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->clip==1.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->clip==1.0) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->clip==1.0) (1.3.0)\n",
            "Building wheels for collected packages: clip\n",
            "  Building wheel for clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for clip: filename=clip-1.0-py3-none-any.whl size=1369497 sha256=35af34a24820af35b90a29a879fa9f31f52a534a57b513bfe5f3b0965778c68f\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-fc8l_rd6/wheels/da/2b/4c/d6691fa9597aac8bb85d2ac13b112deb897d5b50f5ad9a37e4\n",
            "Successfully built clip\n",
            "Installing collected packages: ftfy, clip\n",
            "\u001b[33m  WARNING: The script ftfy is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0mSuccessfully installed clip-1.0 ftfy-6.2.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "clip"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from cleanfid import fid\n",
        "\n",
        "fake_image_path = \"results-ssim\" # replace this with the model extension folder you want to test\n",
        "\n",
        "real_image_path = \"combined_images\"\n",
        "\n",
        "from cleanfid import fid\n",
        "clip_score = fid.compute_fid(fake_image_path, real_image_path, mode=\"clean\", model_name=\"clip_vit_b_32\")\n",
        "print(\"ClIP score:\", clip_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8xUKIHUoixGa",
        "outputId": "6eef02cb-e570-4eb7-b9c3-aca387f4b92a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "compute FID between two folders\n",
            "Found 1006 images in the folder results-ssim\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "FID results-ssim : 100%|██████████| 32/32 [00:08<00:00,  3.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1006 images in the folder combined_images\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "FID combined_images : 100%|██████████| 32/32 [00:08<00:00,  3.86it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(clip_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vp1paNirj2Zz",
        "outputId": "4ccb9507-662e-4251-8940-20ecfabf32d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11.438160002507388\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pose Estimation"
      ],
      "metadata": {
        "id": "kdlK8IjdoXEI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import dlib\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Load Dlib's face detector and facial landmark predictor\n",
        "detector = dlib.get_frontal_face_detector()\n",
        "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")  # Download this file from Dlib's website\n",
        "\n",
        "def calculate_pose_metric(original_poses, generated_poses):\n",
        "    \"\"\"\n",
        "    Calculate pose metric using averaged L2 distance between original and generated poses.\n",
        "\n",
        "    Parameters:\n",
        "    - original_poses: List or array of original poses.\n",
        "    - generated_poses: List or array of generated poses.\n",
        "\n",
        "    Returns:\n",
        "    - pose_metric: Averaged L2 distance between original and generated poses.\n",
        "    \"\"\"\n",
        "    # Convert pose lists to numpy arrays for easier computation\n",
        "    original_poses = np.array(original_poses)\n",
        "    generated_poses = np.array(generated_poses)\n",
        "\n",
        "    # Calculate L2 distances between corresponding poses\n",
        "    l2_distances = np.linalg.norm(original_poses - generated_poses, axis=1)\n",
        "\n",
        "    # Compute the average L2 distance\n",
        "    pose_metric = np.mean(l2_distances)\n",
        "\n",
        "    return pose_metric\n",
        "\n",
        "def get_landmarks(image_path):\n",
        "    # Load the input image\n",
        "    image = cv2.imread(image_path)\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Detect faces in the image\n",
        "    faces = detector(gray)\n",
        "\n",
        "    if len(faces) == 0:\n",
        "        print(\"No faces detected in the image.\")\n",
        "        return None\n",
        "\n",
        "    # Assume there's only one face in the image (you can modify this if needed)\n",
        "    face = faces[0]\n",
        "\n",
        "    # Detect facial landmarks\n",
        "    landmarks = predictor(gray, face)\n",
        "    landmarks = np.array([(landmark.x, landmark.y) for landmark in landmarks.parts()])\n",
        "    return landmarks\n",
        "\n",
        "\n",
        "def estimate_pose(image_path, gen_image_path):\n",
        "    landmarks = get_landmarks(image_path)\n",
        "    generated_landmarks = get_landmarks(gen_image_path)\n",
        "\n",
        "\n",
        "    # Calculate the pose metric (e.g., using angles or vectors)\n",
        "    # Here, you can compute the pose metric based on the detected landmarks\n",
        "    pose_metric = calculate_pose_metric(landmarks, generated_landmarks)\n",
        "    return pose_metric\n",
        "\n",
        "\n",
        "# Example usage:\n",
        "image_path = \"/content/idl-project/SimSwap/target/008.jpg\"\n",
        "gen_image_path = \"/content/idl-project/SimSwap/results-ssim/ssim-loss_000_to_008.jpg\"\n",
        "estimated_pose = estimate_pose(image_path, gen_image_path)\n",
        "if estimated_pose is not None:\n",
        "    print(\"Estimated pose metric:\", estimated_pose)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NiNDSh9CoYXD",
        "outputId": "fe3c6258-16d0-4135-ae09-3646c8877f73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estimated pose metric: 1.652406243789865\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PSNR"
      ],
      "metadata": {
        "id": "EH64Ca-gu0_Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "def calculate_psnr(img1, img2):\n",
        "    \"\"\"\n",
        "    Calculate Peak Signal-to-Noise Ratio (PSNR) between two images.\n",
        "\n",
        "    Args:\n",
        "        img1: First image (numpy array).\n",
        "        img2: Second image (numpy array).\n",
        "\n",
        "    Returns:\n",
        "        PSNR value.\n",
        "    \"\"\"\n",
        "    # Resize images to match dimensions if necessary\n",
        "    if img1.shape != img2.shape:\n",
        "        img2 = cv2.resize(img2, (img1.shape[1], img1.shape[0]))\n",
        "\n",
        "    mse = np.mean((img1 - img2) ** 2)\n",
        "    if mse == 0:\n",
        "        return float('inf')\n",
        "    max_pixel = 255.0\n",
        "    psnr = 20 * np.log10(max_pixel / np.sqrt(mse))\n",
        "    return psnr\n",
        "\n",
        "def compute_average_psnr(generated_images_path, source_images_path):\n",
        "    \"\"\"\n",
        "    Compute the average PSNR for a set of generated images.\n",
        "\n",
        "    Args:\n",
        "        generated_images_path: Path to the directory containing generated images.\n",
        "        source_images_path: Path to the directory containing source images.\n",
        "\n",
        "    Returns:\n",
        "        Average PSNR value.\n",
        "    \"\"\"\n",
        "    total_psnr = 0.0\n",
        "    num_images = 0\n",
        "\n",
        "    # Get list of generated image files\n",
        "    generated_image_files = [f for f in os.listdir(generated_images_path) if f.endswith('.jpg') or f.endswith('.png')]\n",
        "\n",
        "    # Initialize tqdm progress bar\n",
        "    progress_bar = tqdm(total=len(generated_image_files), desc='Calculating PSNR', unit='image')\n",
        "\n",
        "    # Iterate through each generated image\n",
        "    for generated_image_file in generated_image_files:\n",
        "        generated_image_path = os.path.join(generated_images_path, generated_image_file)\n",
        "        source_image_name = generated_image_file.split('_')[1] + \".jpg\"\n",
        "        source_image_path = os.path.join(source_images_path, source_image_name)\n",
        "        # print(\"source image path\", source_image_path)\n",
        "\n",
        "        if os.path.exists(source_image_path):\n",
        "            # Read images\n",
        "            generated_image = cv2.imread(generated_image_path)\n",
        "            source_image = cv2.imread(source_image_path)\n",
        "\n",
        "            # Calculate PSNR\n",
        "            psnr = calculate_psnr(generated_image, source_image)\n",
        "            total_psnr += psnr\n",
        "            num_images += 1\n",
        "\n",
        "        # Update progress bar\n",
        "        progress_bar.update(1)\n",
        "\n",
        "    # Close progress bar\n",
        "    progress_bar.close()\n",
        "\n",
        "    if num_images == 0:\n",
        "        return 0.0  # No images found\n",
        "\n",
        "    average_psnr = total_psnr / num_images\n",
        "    return average_psnr\n",
        "\n",
        "generated_images_path = '/content/idl-project/SimSwap/results-simswap/'\n",
        "source_images_path = '/content/idl-project/SimSwap/combined_images/'\n",
        "\n",
        "average_psnr = compute_average_psnr(generated_images_path, source_images_path)\n",
        "print(\"Average PSNR for baseline:\", average_psnr)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "thP2-dy0bMAV",
        "outputId": "cacb1782-1d22-43cb-d3c4-2ab80c43e34a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Calculating PSNR:   0%|          | 0/1006 [00:00<?, ?image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:   1%|          | 6/1006 [00:00<00:20, 49.59image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:   1%|          | 11/1006 [00:00<00:25, 38.95image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:   2%|▏         | 16/1006 [00:00<00:23, 41.49image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:   2%|▏         | 21/1006 [00:00<00:24, 40.10image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:   3%|▎         | 26/1006 [00:00<00:24, 40.13image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:   3%|▎         | 31/1006 [00:00<00:23, 42.34image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:   4%|▎         | 36/1006 [00:00<00:23, 41.25image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:   4%|▍         | 41/1006 [00:00<00:22, 43.27image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:   5%|▍         | 47/1006 [00:01<00:22, 43.05image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:   5%|▌         | 52/1006 [00:01<00:23, 41.29image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:   6%|▌         | 59/1006 [00:01<00:21, 44.58image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:   6%|▋         | 64/1006 [00:01<00:21, 43.99image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:   7%|▋         | 69/1006 [00:01<00:21, 44.09image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:   7%|▋         | 74/1006 [00:01<00:20, 45.18image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:   8%|▊         | 80/1006 [00:01<00:18, 48.86image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:   8%|▊         | 85/1006 [00:01<00:18, 48.80image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:   9%|▉         | 90/1006 [00:02<00:19, 47.83image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:   9%|▉         | 95/1006 [00:02<00:19, 47.62image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  10%|▉         | 100/1006 [00:02<00:19, 47.06image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  11%|█         | 106/1006 [00:02<00:18, 48.53image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  11%|█         | 111/1006 [00:02<00:19, 46.65image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  12%|█▏        | 117/1006 [00:02<00:19, 45.89image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  12%|█▏        | 122/1006 [00:02<00:21, 41.02image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  13%|█▎        | 127/1006 [00:02<00:21, 41.66image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  13%|█▎        | 132/1006 [00:03<00:22, 38.38image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  14%|█▎        | 137/1006 [00:03<00:21, 40.45image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  14%|█▍        | 144/1006 [00:03<00:18, 47.50image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  15%|█▍        | 150/1006 [00:03<00:18, 47.54image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  15%|█▌        | 155/1006 [00:03<00:18, 45.34image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  16%|█▌        | 161/1006 [00:03<00:17, 47.19image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  17%|█▋        | 166/1006 [00:03<00:19, 43.75image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  17%|█▋        | 171/1006 [00:03<00:20, 40.16image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  18%|█▊        | 178/1006 [00:04<00:18, 45.91image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  18%|█▊        | 186/1006 [00:04<00:15, 53.39image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  19%|█▉        | 192/1006 [00:04<00:18, 44.46image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  20%|█▉        | 198/1006 [00:04<00:16, 47.80image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  20%|██        | 204/1006 [00:04<00:18, 44.35image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  21%|██        | 209/1006 [00:04<00:20, 39.79image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  21%|██▏       | 214/1006 [00:04<00:19, 40.99image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  22%|██▏       | 219/1006 [00:04<00:19, 39.95image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  22%|██▏       | 224/1006 [00:05<00:19, 39.33image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  23%|██▎       | 232/1006 [00:05<00:16, 46.67image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  24%|██▎       | 238/1006 [00:05<00:16, 47.12image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  24%|██▍       | 243/1006 [00:05<00:17, 44.53image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  25%|██▍       | 248/1006 [00:05<00:17, 42.90image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  25%|██▌       | 253/1006 [00:05<00:18, 39.92image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  26%|██▌       | 258/1006 [00:05<00:18, 39.41image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  26%|██▌       | 264/1006 [00:06<00:16, 44.03image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  27%|██▋       | 270/1006 [00:06<00:15, 47.34image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  27%|██▋       | 276/1006 [00:06<00:14, 50.29image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  28%|██▊       | 282/1006 [00:06<00:17, 42.32image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  29%|██▉       | 290/1006 [00:06<00:14, 47.92image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  29%|██▉       | 296/1006 [00:06<00:14, 48.27image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  30%|██▉       | 301/1006 [00:06<00:15, 46.19image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  30%|███       | 306/1006 [00:06<00:15, 44.81image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  31%|███       | 313/1006 [00:07<00:14, 46.83image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  32%|███▏      | 318/1006 [00:07<00:15, 45.77image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  32%|███▏      | 323/1006 [00:07<00:15, 44.28image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  33%|███▎      | 328/1006 [00:07<00:15, 44.94image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  33%|███▎      | 335/1006 [00:07<00:13, 50.15image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  34%|███▍      | 342/1006 [00:07<00:12, 54.04image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  35%|███▍      | 348/1006 [00:07<00:13, 50.61image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  35%|███▌      | 354/1006 [00:07<00:12, 51.04image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  36%|███▌      | 360/1006 [00:07<00:12, 50.44image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  36%|███▋      | 366/1006 [00:08<00:14, 44.85image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  37%|███▋      | 372/1006 [00:08<00:14, 44.91image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  37%|███▋      | 377/1006 [00:08<00:13, 45.18image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  38%|███▊      | 382/1006 [00:08<00:14, 42.85image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  39%|███▊      | 388/1006 [00:08<00:14, 43.31image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  39%|███▉      | 393/1006 [00:08<00:16, 36.54image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  40%|███▉      | 398/1006 [00:08<00:15, 39.25image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  40%|████      | 403/1006 [00:09<00:16, 36.08image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  41%|████      | 408/1006 [00:09<00:15, 38.99image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  41%|████      | 413/1006 [00:09<00:14, 40.92image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  42%|████▏     | 418/1006 [00:09<00:14, 39.81image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  42%|████▏     | 423/1006 [00:09<00:14, 39.39image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  43%|████▎     | 429/1006 [00:09<00:13, 42.39image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  43%|████▎     | 434/1006 [00:09<00:13, 41.14image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  44%|████▎     | 439/1006 [00:09<00:14, 38.63image/s]\u001b[A\u001b[A\n",
            "Calculating PSNR:  30%|██▉       | 299/1006 [00:21<00:14, 47.98image/s]\u001b[A\n",
            "\n",
            "Calculating PSNR:  44%|████▍     | 444/1006 [00:10<00:14, 39.57image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  45%|████▍     | 450/1006 [00:10<00:12, 43.50image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  45%|████▌     | 456/1006 [00:10<00:11, 46.29image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  46%|████▌     | 461/1006 [00:10<00:11, 45.73image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  46%|████▋     | 466/1006 [00:10<00:11, 46.36image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  47%|████▋     | 472/1006 [00:10<00:10, 49.90image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  48%|████▊     | 478/1006 [00:10<00:12, 43.76image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  48%|████▊     | 483/1006 [00:10<00:11, 43.89image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  49%|████▊     | 489/1006 [00:11<00:10, 47.15image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  49%|████▉     | 495/1006 [00:11<00:10, 48.75image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  50%|████▉     | 501/1006 [00:11<00:09, 51.50image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  50%|█████     | 507/1006 [00:11<00:11, 41.82image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  51%|█████     | 512/1006 [00:11<00:12, 39.85image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  51%|█████▏    | 517/1006 [00:11<00:12, 39.00image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  52%|█████▏    | 522/1006 [00:11<00:11, 41.18image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  52%|█████▏    | 528/1006 [00:11<00:10, 45.34image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  53%|█████▎    | 536/1006 [00:12<00:09, 50.94image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  54%|█████▍    | 542/1006 [00:12<00:10, 45.42image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  54%|█████▍    | 548/1006 [00:12<00:09, 47.76image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  55%|█████▍    | 553/1006 [00:12<00:09, 46.39image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  56%|█████▌    | 561/1006 [00:12<00:09, 48.29image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  56%|█████▋    | 567/1006 [00:12<00:08, 49.46image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  57%|█████▋    | 572/1006 [00:12<00:09, 46.88image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  57%|█████▋    | 577/1006 [00:12<00:09, 44.53image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  58%|█████▊    | 582/1006 [00:13<00:09, 43.98image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  58%|█████▊    | 587/1006 [00:13<00:09, 42.70image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  59%|█████▉    | 593/1006 [00:13<00:09, 43.38image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  60%|█████▉    | 599/1006 [00:13<00:08, 46.72image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  60%|██████    | 604/1006 [00:13<00:08, 45.26image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  61%|██████    | 609/1006 [00:13<00:08, 44.58image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  61%|██████    | 614/1006 [00:13<00:09, 42.76image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  62%|██████▏   | 619/1006 [00:13<00:08, 43.79image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  62%|██████▏   | 624/1006 [00:14<00:08, 42.99image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  63%|██████▎   | 630/1006 [00:14<00:07, 47.47image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  63%|██████▎   | 635/1006 [00:14<00:08, 44.17image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  64%|██████▎   | 640/1006 [00:14<00:09, 40.26image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  64%|██████▍   | 645/1006 [00:14<00:08, 40.67image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  65%|██████▍   | 650/1006 [00:14<00:08, 42.58image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  65%|██████▌   | 655/1006 [00:14<00:09, 36.71image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  66%|██████▌   | 659/1006 [00:15<00:10, 33.77image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  66%|██████▌   | 666/1006 [00:15<00:08, 41.41image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  67%|██████▋   | 671/1006 [00:15<00:08, 41.72image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  67%|██████▋   | 676/1006 [00:15<00:08, 39.34image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  68%|██████▊   | 684/1006 [00:15<00:06, 46.21image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  69%|██████▊   | 690/1006 [00:15<00:06, 48.78image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  69%|██████▉   | 696/1006 [00:15<00:06, 48.59image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  70%|██████▉   | 702/1006 [00:15<00:06, 50.11image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  70%|███████   | 709/1006 [00:15<00:05, 53.67image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  71%|███████   | 715/1006 [00:16<00:05, 49.36image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  72%|███████▏  | 721/1006 [00:16<00:05, 49.00image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  72%|███████▏  | 727/1006 [00:16<00:05, 51.53image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  73%|███████▎  | 734/1006 [00:16<00:04, 55.08image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  74%|███████▎  | 740/1006 [00:16<00:04, 56.01image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  74%|███████▍  | 747/1006 [00:16<00:04, 56.72image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  75%|███████▍  | 753/1006 [00:16<00:04, 51.54image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  75%|███████▌  | 759/1006 [00:16<00:04, 50.80image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  76%|███████▌  | 765/1006 [00:17<00:05, 45.18image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  77%|███████▋  | 770/1006 [00:17<00:05, 46.21image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  77%|███████▋  | 775/1006 [00:17<00:04, 46.69image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  78%|███████▊  | 780/1006 [00:17<00:04, 46.75image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  78%|███████▊  | 785/1006 [00:17<00:04, 47.30image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  79%|███████▉  | 793/1006 [00:17<00:03, 55.55image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  79%|███████▉  | 799/1006 [00:17<00:04, 46.81image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  80%|████████  | 805/1006 [00:17<00:04, 48.52image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  81%|████████  | 811/1006 [00:18<00:04, 45.77image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  81%|████████  | 816/1006 [00:18<00:04, 45.68image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  82%|████████▏ | 822/1006 [00:18<00:03, 48.45image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  82%|████████▏ | 829/1006 [00:18<00:03, 53.75image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  83%|████████▎ | 835/1006 [00:18<00:03, 51.87image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  84%|████████▎ | 841/1006 [00:18<00:03, 48.76image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  84%|████████▍ | 846/1006 [00:18<00:03, 41.51image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  85%|████████▍ | 851/1006 [00:18<00:03, 39.01image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  85%|████████▌ | 856/1006 [00:19<00:03, 41.13image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  86%|████████▌ | 862/1006 [00:19<00:03, 41.81image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  86%|████████▋ | 869/1006 [00:19<00:02, 46.73image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  87%|████████▋ | 875/1006 [00:19<00:02, 49.38image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  88%|████████▊ | 881/1006 [00:19<00:02, 51.78image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  88%|████████▊ | 889/1006 [00:19<00:02, 58.24image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  89%|████████▉ | 895/1006 [00:19<00:02, 47.81image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  90%|████████▉ | 901/1006 [00:19<00:02, 43.92image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  90%|█████████ | 906/1006 [00:20<00:02, 44.81image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  91%|█████████ | 911/1006 [00:20<00:02, 43.37image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  91%|█████████ | 917/1006 [00:20<00:02, 42.31image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  92%|█████████▏| 922/1006 [00:20<00:02, 39.00image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  92%|█████████▏| 927/1006 [00:20<00:01, 41.34image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  93%|█████████▎| 932/1006 [00:20<00:01, 39.75image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  93%|█████████▎| 938/1006 [00:20<00:01, 44.12image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  94%|█████████▎| 943/1006 [00:21<00:01, 41.28image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  94%|█████████▍| 948/1006 [00:21<00:01, 41.68image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  95%|█████████▍| 954/1006 [00:21<00:01, 45.71image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  95%|█████████▌| 959/1006 [00:21<00:01, 43.88image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  96%|█████████▌| 964/1006 [00:21<00:00, 44.76image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  96%|█████████▋| 970/1006 [00:21<00:00, 48.36image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  97%|█████████▋| 975/1006 [00:21<00:00, 42.07image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  97%|█████████▋| 980/1006 [00:21<00:00, 36.72image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  98%|█████████▊| 986/1006 [00:22<00:00, 41.35image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  99%|█████████▊| 991/1006 [00:22<00:00, 42.04image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  99%|█████████▉| 997/1006 [00:22<00:00, 44.90image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR: 100%|██████████| 1006/1006 [00:22<00:00, 44.88image/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average PSNR for baseline: 27.937155448921903\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generated_images_path = '/content/idl-project/SimSwap/results-eca/'\n",
        "source_images_path = '/content/idl-project/SimSwap/combined_images/'\n",
        "\n",
        "average_psnr = compute_average_psnr(generated_images_path, source_images_path)\n",
        "print(\"Average PSNR for ECA extension:\", average_psnr)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXpJ0V_pe4LO",
        "outputId": "64f566d7-743c-4aac-8672-e2ec99eb025c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Calculating PSNR:   0%|          | 0/1006 [00:00<?, ?image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:   0%|          | 5/1006 [00:00<00:21, 46.70image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:   1%|          | 11/1006 [00:00<00:21, 46.83image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:   2%|▏         | 16/1006 [00:00<00:24, 40.40image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:   2%|▏         | 22/1006 [00:00<00:21, 44.95image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:   3%|▎         | 27/1006 [00:00<00:22, 43.95image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:   3%|▎         | 32/1006 [00:00<00:25, 38.88image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:   4%|▎         | 37/1006 [00:00<00:24, 39.95image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:   4%|▍         | 42/1006 [00:00<00:23, 41.70image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:   5%|▍         | 47/1006 [00:01<00:23, 41.60image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:   5%|▌         | 52/1006 [00:01<00:25, 37.83image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:   6%|▌         | 57/1006 [00:01<00:24, 38.84image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:   6%|▌         | 61/1006 [00:01<00:26, 35.92image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:   6%|▋         | 65/1006 [00:01<00:27, 34.02image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:   7%|▋         | 69/1006 [00:01<00:27, 34.33image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:   7%|▋         | 73/1006 [00:01<00:28, 32.19image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:   8%|▊         | 77/1006 [00:02<00:27, 33.29image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:   8%|▊         | 83/1006 [00:02<00:23, 39.67image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:   9%|▊         | 88/1006 [00:02<00:24, 37.35image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:   9%|▉         | 93/1006 [00:02<00:23, 38.23image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  10%|▉         | 99/1006 [00:02<00:22, 40.91image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  10%|█         | 104/1006 [00:02<00:22, 39.89image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  11%|█         | 110/1006 [00:02<00:20, 43.29image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  11%|█▏        | 115/1006 [00:02<00:19, 44.76image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  12%|█▏        | 120/1006 [00:03<00:20, 44.21image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  12%|█▏        | 125/1006 [00:03<00:19, 45.39image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  13%|█▎        | 131/1006 [00:03<00:19, 44.07image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  14%|█▎        | 137/1006 [00:03<00:18, 47.47image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  14%|█▍        | 144/1006 [00:03<00:16, 51.95image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  15%|█▍        | 150/1006 [00:03<00:17, 48.99image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  15%|█▌        | 155/1006 [00:03<00:19, 44.05image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  16%|█▌        | 160/1006 [00:03<00:21, 39.66image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  17%|█▋        | 166/1006 [00:04<00:19, 43.94image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  17%|█▋        | 173/1006 [00:04<00:17, 47.45image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  18%|█▊        | 179/1006 [00:04<00:17, 46.87image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  18%|█▊        | 184/1006 [00:04<00:21, 38.23image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  19%|█▉        | 189/1006 [00:04<00:21, 38.56image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  19%|█▉        | 194/1006 [00:04<00:20, 39.84image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  20%|█▉        | 199/1006 [00:04<00:20, 38.92image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  20%|██        | 204/1006 [00:04<00:20, 38.29image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  21%|██        | 209/1006 [00:05<00:19, 40.32image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  21%|██▏       | 214/1006 [00:05<00:20, 38.00image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  22%|██▏       | 218/1006 [00:05<00:21, 37.29image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  22%|██▏       | 222/1006 [00:05<00:21, 36.93image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  22%|██▏       | 226/1006 [00:05<00:21, 35.83image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  23%|██▎       | 230/1006 [00:05<00:22, 34.26image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  23%|██▎       | 236/1006 [00:05<00:19, 40.44image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  24%|██▍       | 241/1006 [00:05<00:19, 39.63image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  25%|██▍       | 247/1006 [00:06<00:17, 42.67image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  25%|██▌       | 253/1006 [00:06<00:16, 44.76image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  26%|██▌       | 258/1006 [00:06<00:16, 45.13image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  26%|██▌       | 263/1006 [00:06<00:17, 42.58image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  27%|██▋       | 268/1006 [00:06<00:17, 42.79image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  27%|██▋       | 274/1006 [00:06<00:16, 43.72image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  28%|██▊       | 279/1006 [00:06<00:19, 37.69image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  28%|██▊       | 285/1006 [00:06<00:17, 42.12image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  29%|██▉       | 290/1006 [00:07<00:17, 39.96image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  29%|██▉       | 295/1006 [00:07<00:17, 40.05image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  30%|██▉       | 300/1006 [00:07<00:16, 42.12image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  30%|███       | 305/1006 [00:07<00:16, 41.69image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  31%|███       | 310/1006 [00:07<00:16, 41.57image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  31%|███▏      | 316/1006 [00:07<00:15, 43.46image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  32%|███▏      | 321/1006 [00:07<00:15, 44.05image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  33%|███▎      | 327/1006 [00:07<00:14, 45.97image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  33%|███▎      | 332/1006 [00:08<00:15, 42.72image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  33%|███▎      | 337/1006 [00:08<00:16, 41.77image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  34%|███▍      | 343/1006 [00:08<00:14, 46.19image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  35%|███▍      | 349/1006 [00:08<00:13, 48.22image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  35%|███▌      | 354/1006 [00:08<00:14, 44.56image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  36%|███▌      | 359/1006 [00:08<00:14, 44.41image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  36%|███▌      | 364/1006 [00:08<00:15, 41.10image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  37%|███▋      | 369/1006 [00:08<00:15, 42.33image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  37%|███▋      | 375/1006 [00:09<00:13, 45.30image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  38%|███▊      | 382/1006 [00:09<00:12, 49.04image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  39%|███▊      | 389/1006 [00:09<00:12, 49.41image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  39%|███▉      | 397/1006 [00:09<00:10, 56.90image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  40%|████      | 403/1006 [00:09<00:12, 49.83image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  41%|████      | 409/1006 [00:09<00:12, 49.42image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  41%|████▏     | 415/1006 [00:09<00:11, 52.04image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  42%|████▏     | 421/1006 [00:09<00:13, 43.87image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  42%|████▏     | 427/1006 [00:10<00:12, 46.39image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  43%|████▎     | 432/1006 [00:10<00:14, 40.12image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  43%|████▎     | 437/1006 [00:10<00:13, 41.19image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  44%|████▍     | 442/1006 [00:10<00:13, 43.12image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  44%|████▍     | 447/1006 [00:10<00:15, 37.04image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  45%|████▌     | 454/1006 [00:10<00:12, 43.62image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  46%|████▌     | 459/1006 [00:10<00:12, 44.37image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  46%|████▌     | 464/1006 [00:11<00:15, 35.62image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  47%|████▋     | 469/1006 [00:11<00:14, 36.05image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  47%|████▋     | 474/1006 [00:11<00:14, 36.81image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  48%|████▊     | 482/1006 [00:11<00:11, 46.45image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  49%|████▊     | 488/1006 [00:11<00:12, 42.45image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  49%|████▉     | 493/1006 [00:11<00:11, 43.88image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  50%|████▉     | 498/1006 [00:11<00:12, 41.73image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  50%|█████     | 503/1006 [00:11<00:12, 41.05image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  50%|█████     | 508/1006 [00:12<00:12, 40.32image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  51%|█████     | 513/1006 [00:12<00:13, 36.45image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  51%|█████▏    | 517/1006 [00:12<00:13, 36.45image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  52%|█████▏    | 524/1006 [00:12<00:11, 43.75image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  53%|█████▎    | 531/1006 [00:12<00:09, 49.57image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  53%|█████▎    | 537/1006 [00:12<00:11, 40.46image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  54%|█████▍    | 542/1006 [00:12<00:11, 39.66image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  54%|█████▍    | 548/1006 [00:13<00:11, 41.10image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  55%|█████▍    | 553/1006 [00:13<00:10, 41.79image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  55%|█████▌    | 558/1006 [00:13<00:11, 40.23image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  56%|█████▌    | 563/1006 [00:13<00:10, 41.45image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  56%|█████▋    | 568/1006 [00:13<00:10, 43.10image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  57%|█████▋    | 574/1006 [00:13<00:09, 47.10image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  58%|█████▊    | 580/1006 [00:13<00:08, 48.30image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  58%|█████▊    | 587/1006 [00:13<00:07, 53.43image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  59%|█████▉    | 593/1006 [00:14<00:07, 51.96image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  60%|█████▉    | 599/1006 [00:14<00:08, 47.82image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  60%|██████    | 605/1006 [00:14<00:08, 48.87image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  61%|██████    | 610/1006 [00:14<00:08, 45.48image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  61%|██████    | 615/1006 [00:14<00:08, 44.86image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  62%|██████▏   | 620/1006 [00:14<00:09, 41.87image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  62%|██████▏   | 625/1006 [00:14<00:09, 38.57image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  63%|██████▎   | 631/1006 [00:14<00:09, 40.22image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  63%|██████▎   | 636/1006 [00:15<00:09, 37.61image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  64%|██████▍   | 642/1006 [00:15<00:08, 40.78image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  64%|██████▍   | 648/1006 [00:15<00:08, 44.73image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  65%|██████▍   | 653/1006 [00:15<00:08, 43.10image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  65%|██████▌   | 658/1006 [00:15<00:08, 39.33image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  66%|██████▌   | 663/1006 [00:15<00:09, 36.16image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  66%|██████▋   | 668/1006 [00:15<00:08, 38.34image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  67%|██████▋   | 673/1006 [00:16<00:08, 40.44image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  67%|██████▋   | 678/1006 [00:16<00:08, 39.48image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  68%|██████▊   | 683/1006 [00:16<00:07, 41.65image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  68%|██████▊   | 689/1006 [00:16<00:07, 45.02image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  69%|██████▉   | 694/1006 [00:16<00:07, 42.60image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  70%|██████▉   | 701/1006 [00:16<00:06, 46.33image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  70%|███████   | 706/1006 [00:16<00:06, 45.43image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  71%|███████   | 711/1006 [00:16<00:06, 44.31image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  71%|███████   | 716/1006 [00:16<00:06, 42.31image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  72%|███████▏  | 721/1006 [00:17<00:06, 43.68image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  72%|███████▏  | 726/1006 [00:17<00:07, 38.91image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  73%|███████▎  | 731/1006 [00:17<00:06, 40.53image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  73%|███████▎  | 737/1006 [00:17<00:06, 41.70image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  74%|███████▍  | 742/1006 [00:17<00:06, 40.06image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  74%|███████▍  | 748/1006 [00:17<00:05, 43.53image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  75%|███████▍  | 754/1006 [00:17<00:05, 45.14image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  75%|███████▌  | 759/1006 [00:18<00:05, 42.61image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  76%|███████▌  | 764/1006 [00:18<00:05, 42.78image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  76%|███████▋  | 769/1006 [00:18<00:05, 44.39image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  77%|███████▋  | 774/1006 [00:18<00:06, 37.83image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  77%|███████▋  | 779/1006 [00:18<00:05, 39.08image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  78%|███████▊  | 784/1006 [00:18<00:05, 41.31image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  78%|███████▊  | 789/1006 [00:18<00:05, 42.84image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  79%|███████▉  | 794/1006 [00:18<00:04, 44.04image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  80%|███████▉  | 800/1006 [00:18<00:04, 46.92image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  80%|████████  | 805/1006 [00:19<00:04, 43.73image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  81%|████████  | 810/1006 [00:19<00:04, 44.97image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  81%|████████  | 815/1006 [00:19<00:04, 45.23image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  82%|████████▏ | 820/1006 [00:19<00:04, 45.01image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  82%|████████▏ | 826/1006 [00:19<00:03, 47.60image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  83%|████████▎ | 831/1006 [00:19<00:03, 45.56image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  83%|████████▎ | 837/1006 [00:19<00:03, 48.72image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  84%|████████▎ | 842/1006 [00:19<00:03, 48.15image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  84%|████████▍ | 848/1006 [00:19<00:03, 49.26image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  85%|████████▍ | 853/1006 [00:20<00:03, 44.24image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  85%|████████▌ | 858/1006 [00:20<00:03, 43.70image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  86%|████████▌ | 864/1006 [00:20<00:03, 46.58image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  86%|████████▋ | 869/1006 [00:20<00:03, 42.61image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  87%|████████▋ | 875/1006 [00:20<00:02, 46.26image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  88%|████████▊ | 881/1006 [00:20<00:02, 49.35image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  88%|████████▊ | 887/1006 [00:20<00:02, 49.69image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  89%|████████▉ | 894/1006 [00:20<00:02, 52.79image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  89%|████████▉ | 900/1006 [00:21<00:01, 53.28image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  90%|█████████ | 906/1006 [00:21<00:01, 52.39image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  91%|█████████ | 912/1006 [00:21<00:01, 50.38image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  91%|█████████▏| 918/1006 [00:21<00:01, 50.20image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  92%|█████████▏| 924/1006 [00:21<00:01, 52.38image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  92%|█████████▏| 930/1006 [00:21<00:01, 53.97image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  93%|█████████▎| 936/1006 [00:21<00:01, 44.43image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  94%|█████████▎| 941/1006 [00:21<00:01, 45.52image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  94%|█████████▍| 946/1006 [00:22<00:01, 43.54image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  95%|█████████▍| 951/1006 [00:22<00:01, 43.58image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  95%|█████████▌| 957/1006 [00:22<00:01, 47.46image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  96%|█████████▌| 963/1006 [00:22<00:00, 48.21image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  96%|█████████▋| 969/1006 [00:22<00:00, 50.82image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  97%|█████████▋| 975/1006 [00:22<00:00, 51.47image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  98%|█████████▊| 981/1006 [00:22<00:00, 42.15image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  98%|█████████▊| 986/1006 [00:22<00:00, 38.71image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  99%|█████████▊| 991/1006 [00:23<00:00, 40.97image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  99%|█████████▉| 997/1006 [00:23<00:00, 44.62image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR: 100%|██████████| 1006/1006 [00:23<00:00, 42.94image/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average PSNR for ECA extension: 27.93658239336135\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generated_images_path = '/content/idl-project/SimSwap/results/'\n",
        "source_images_path = '/content/idl-project/SimSwap/combined_images/'\n",
        "\n",
        "average_psnr = compute_average_psnr(generated_images_path, source_images_path)\n",
        "print(\"Average PSNR for perceptual loss extension:\", average_psnr)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rp-NMo58fF0p",
        "outputId": "d721b029-cdab-4bf6-e7bf-4096f5d2f14b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Calculating PSNR:   0%|          | 0/1006 [00:00<?, ?image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:   1%|          | 6/1006 [00:00<00:21, 46.86image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:   1%|          | 11/1006 [00:00<00:20, 47.53image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:   2%|▏         | 17/1006 [00:00<00:19, 50.75image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:   2%|▏         | 23/1006 [00:00<00:22, 44.40image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:   3%|▎         | 28/1006 [00:00<00:25, 38.40image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:   3%|▎         | 32/1006 [00:00<00:25, 37.93image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:   4%|▍         | 38/1006 [00:00<00:22, 42.57image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:   4%|▍         | 44/1006 [00:00<00:20, 46.08image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:   5%|▍         | 49/1006 [00:01<00:20, 46.08image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:   5%|▌         | 54/1006 [00:01<00:21, 43.88image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:   6%|▌         | 59/1006 [00:01<00:22, 41.69image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:   6%|▋         | 64/1006 [00:01<00:23, 40.33image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:   7%|▋         | 70/1006 [00:01<00:22, 41.37image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:   7%|▋         | 75/1006 [00:01<00:22, 41.85image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:   8%|▊         | 81/1006 [00:01<00:20, 44.75image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:   9%|▊         | 86/1006 [00:02<00:21, 42.11image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:   9%|▉         | 92/1006 [00:02<00:20, 45.43image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  10%|▉         | 97/1006 [00:02<00:22, 39.83image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  10%|█         | 102/1006 [00:02<00:24, 36.75image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  11%|█         | 106/1006 [00:02<00:24, 36.45image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  11%|█         | 110/1006 [00:02<00:24, 36.14image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  11%|█▏        | 114/1006 [00:02<00:25, 34.81image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  12%|█▏        | 118/1006 [00:02<00:25, 34.66image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  12%|█▏        | 122/1006 [00:03<00:26, 32.92image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  13%|█▎        | 127/1006 [00:03<00:23, 36.88image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  13%|█▎        | 131/1006 [00:03<00:23, 37.70image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  14%|█▎        | 136/1006 [00:03<00:21, 40.02image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  14%|█▍        | 141/1006 [00:03<00:21, 40.68image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  15%|█▍        | 147/1006 [00:03<00:19, 44.27image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  15%|█▌        | 152/1006 [00:03<00:18, 45.26image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  16%|█▌        | 158/1006 [00:03<00:18, 46.36image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  16%|█▌        | 163/1006 [00:03<00:19, 43.50image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  17%|█▋        | 168/1006 [00:04<00:21, 39.67image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  17%|█▋        | 173/1006 [00:04<00:20, 40.00image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  18%|█▊        | 178/1006 [00:04<00:19, 42.19image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  18%|█▊        | 184/1006 [00:04<00:17, 45.88image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  19%|█▉        | 189/1006 [00:04<00:17, 46.09image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  19%|█▉        | 194/1006 [00:04<00:18, 44.81image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  20%|█▉        | 199/1006 [00:04<00:21, 37.34image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  20%|██        | 203/1006 [00:04<00:21, 37.25image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  21%|██        | 209/1006 [00:05<00:19, 41.92image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  21%|██▏       | 214/1006 [00:05<00:20, 39.05image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  22%|██▏       | 219/1006 [00:05<00:19, 39.76image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  22%|██▏       | 224/1006 [00:05<00:20, 38.03image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  23%|██▎       | 228/1006 [00:05<00:21, 36.38image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  23%|██▎       | 232/1006 [00:05<00:21, 36.51image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  23%|██▎       | 236/1006 [00:05<00:22, 34.10image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  24%|██▍       | 240/1006 [00:05<00:22, 34.16image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  24%|██▍       | 244/1006 [00:06<00:22, 33.75image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  25%|██▍       | 248/1006 [00:06<00:22, 33.85image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  25%|██▌       | 253/1006 [00:06<00:20, 35.87image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  26%|██▌       | 258/1006 [00:06<00:20, 36.22image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  26%|██▌       | 264/1006 [00:06<00:18, 40.33image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  27%|██▋       | 271/1006 [00:06<00:15, 47.92image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  27%|██▋       | 276/1006 [00:06<00:15, 48.06image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  28%|██▊       | 282/1006 [00:06<00:14, 50.76image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  29%|██▊       | 288/1006 [00:07<00:15, 46.79image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  29%|██▉       | 294/1006 [00:07<00:14, 49.81image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  30%|██▉       | 300/1006 [00:07<00:15, 45.82image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  30%|███       | 305/1006 [00:07<00:17, 40.16image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  31%|███       | 310/1006 [00:07<00:17, 39.02image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  31%|███▏      | 315/1006 [00:07<00:17, 38.52image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  32%|███▏      | 319/1006 [00:07<00:17, 38.43image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  32%|███▏      | 323/1006 [00:07<00:18, 37.16image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  33%|███▎      | 327/1006 [00:08<00:18, 37.42image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  33%|███▎      | 331/1006 [00:08<00:19, 34.06image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  33%|███▎      | 336/1006 [00:08<00:18, 36.29image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  34%|███▍      | 340/1006 [00:08<00:19, 34.82image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  34%|███▍      | 344/1006 [00:08<00:19, 34.72image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  35%|███▍      | 349/1006 [00:08<00:17, 36.91image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  35%|███▌      | 353/1006 [00:08<00:17, 37.13image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  36%|███▌      | 360/1006 [00:08<00:15, 42.18image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  36%|███▋      | 365/1006 [00:09<00:14, 43.81image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  37%|███▋      | 370/1006 [00:09<00:14, 43.84image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  37%|███▋      | 376/1006 [00:09<00:13, 46.43image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  38%|███▊      | 381/1006 [00:09<00:13, 47.06image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  38%|███▊      | 386/1006 [00:09<00:14, 42.71image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  39%|███▉      | 391/1006 [00:09<00:14, 41.82image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  39%|███▉      | 396/1006 [00:09<00:14, 43.32image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  40%|███▉      | 401/1006 [00:09<00:13, 43.77image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  40%|████      | 406/1006 [00:09<00:13, 45.34image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  41%|████      | 411/1006 [00:10<00:13, 45.37image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  41%|████▏     | 416/1006 [00:10<00:12, 46.30image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  42%|████▏     | 422/1006 [00:10<00:12, 45.63image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  42%|████▏     | 427/1006 [00:10<00:13, 41.85image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  43%|████▎     | 432/1006 [00:10<00:14, 39.63image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  43%|████▎     | 437/1006 [00:10<00:15, 37.93image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  44%|████▍     | 441/1006 [00:10<00:15, 37.29image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  45%|████▍     | 448/1006 [00:10<00:12, 44.64image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  45%|████▌     | 454/1006 [00:11<00:11, 47.73image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  46%|████▌     | 460/1006 [00:11<00:10, 50.20image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  46%|████▋     | 466/1006 [00:11<00:10, 52.24image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  47%|████▋     | 472/1006 [00:11<00:10, 51.71image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  48%|████▊     | 478/1006 [00:11<00:10, 51.47image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  48%|████▊     | 484/1006 [00:11<00:10, 48.68image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  49%|████▊     | 490/1006 [00:11<00:10, 50.44image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  49%|████▉     | 496/1006 [00:11<00:10, 46.49image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  50%|████▉     | 501/1006 [00:12<00:11, 42.60image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  50%|█████     | 506/1006 [00:12<00:11, 42.90image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  51%|█████     | 512/1006 [00:12<00:11, 44.75image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  51%|█████▏    | 517/1006 [00:12<00:11, 42.90image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  52%|█████▏    | 524/1006 [00:12<00:09, 48.67image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  53%|█████▎    | 530/1006 [00:12<00:09, 51.02image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  53%|█████▎    | 536/1006 [00:12<00:09, 49.10image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  54%|█████▍    | 541/1006 [00:12<00:10, 44.04image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  54%|█████▍    | 546/1006 [00:13<00:10, 44.92image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  55%|█████▍    | 551/1006 [00:13<00:10, 44.70image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  55%|█████▌    | 557/1006 [00:13<00:09, 48.48image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  56%|█████▌    | 562/1006 [00:13<00:10, 43.95image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  56%|█████▋    | 568/1006 [00:13<00:09, 47.01image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  57%|█████▋    | 577/1006 [00:13<00:07, 58.02image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  58%|█████▊    | 583/1006 [00:13<00:08, 52.42image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  59%|█████▊    | 589/1006 [00:13<00:09, 43.37image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  59%|█████▉    | 594/1006 [00:14<00:09, 42.61image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  60%|█████▉    | 599/1006 [00:14<00:09, 40.90image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  60%|██████    | 604/1006 [00:14<00:09, 40.49image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  61%|██████    | 609/1006 [00:14<00:09, 41.76image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  61%|██████    | 614/1006 [00:14<00:10, 38.30image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  62%|██████▏   | 621/1006 [00:14<00:08, 44.01image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  62%|██████▏   | 626/1006 [00:14<00:09, 41.80image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  63%|██████▎   | 631/1006 [00:14<00:08, 42.46image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  63%|██████▎   | 636/1006 [00:15<00:08, 41.30image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  64%|██████▎   | 641/1006 [00:15<00:08, 43.12image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  64%|██████▍   | 646/1006 [00:15<00:08, 40.67image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  65%|██████▍   | 651/1006 [00:15<00:08, 42.77image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  65%|██████▌   | 656/1006 [00:15<00:08, 42.65image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  66%|██████▌   | 661/1006 [00:15<00:08, 42.00image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  66%|██████▋   | 667/1006 [00:15<00:07, 46.09image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  67%|██████▋   | 672/1006 [00:15<00:07, 43.17image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  67%|██████▋   | 677/1006 [00:16<00:07, 44.58image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  68%|██████▊   | 684/1006 [00:16<00:06, 49.19image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  69%|██████▊   | 690/1006 [00:16<00:06, 51.56image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  69%|██████▉   | 696/1006 [00:16<00:06, 44.83image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  70%|██████▉   | 703/1006 [00:16<00:06, 50.08image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  70%|███████   | 709/1006 [00:16<00:05, 50.24image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  71%|███████   | 716/1006 [00:16<00:05, 52.74image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  72%|███████▏  | 722/1006 [00:16<00:05, 48.02image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  72%|███████▏  | 728/1006 [00:17<00:05, 49.77image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  73%|███████▎  | 735/1006 [00:17<00:05, 53.76image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  74%|███████▎  | 741/1006 [00:17<00:05, 48.06image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  74%|███████▍  | 747/1006 [00:17<00:05, 50.16image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  75%|███████▍  | 753/1006 [00:17<00:04, 51.12image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  75%|███████▌  | 759/1006 [00:17<00:06, 40.83image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  76%|███████▌  | 764/1006 [00:17<00:06, 39.00image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  76%|███████▋  | 769/1006 [00:18<00:06, 38.23image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  77%|███████▋  | 774/1006 [00:18<00:05, 39.96image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  77%|███████▋  | 779/1006 [00:18<00:05, 42.28image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  78%|███████▊  | 784/1006 [00:18<00:05, 43.07image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  79%|███████▊  | 791/1006 [00:18<00:04, 44.31image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  79%|███████▉  | 797/1006 [00:18<00:04, 47.09image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  80%|███████▉  | 804/1006 [00:18<00:03, 52.43image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  81%|████████  | 811/1006 [00:18<00:03, 56.49image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  81%|████████▏ | 819/1006 [00:18<00:03, 61.22image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  82%|████████▏ | 826/1006 [00:19<00:03, 53.24image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  83%|████████▎ | 832/1006 [00:19<00:03, 53.14image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  83%|████████▎ | 839/1006 [00:19<00:03, 52.10image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  84%|████████▍ | 845/1006 [00:19<00:03, 48.93image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  85%|████████▍ | 851/1006 [00:19<00:03, 47.25image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  85%|████████▌ | 856/1006 [00:19<00:03, 41.03image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  86%|████████▌ | 861/1006 [00:19<00:03, 39.93image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  86%|████████▌ | 866/1006 [00:20<00:03, 40.10image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  87%|████████▋ | 871/1006 [00:20<00:03, 38.18image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  87%|████████▋ | 875/1006 [00:20<00:03, 37.62image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  87%|████████▋ | 880/1006 [00:20<00:03, 40.49image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  88%|████████▊ | 885/1006 [00:20<00:03, 39.19image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  88%|████████▊ | 889/1006 [00:20<00:03, 36.90image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  89%|████████▉ | 893/1006 [00:20<00:03, 37.24image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  89%|████████▉ | 898/1006 [00:20<00:02, 39.54image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  90%|████████▉ | 904/1006 [00:20<00:02, 44.45image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  91%|█████████ | 912/1006 [00:21<00:01, 50.83image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  91%|█████████▏| 919/1006 [00:21<00:01, 54.79image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  92%|█████████▏| 926/1006 [00:21<00:01, 58.92image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  93%|█████████▎| 932/1006 [00:21<00:01, 49.00image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  93%|█████████▎| 938/1006 [00:21<00:01, 50.87image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  94%|█████████▍| 944/1006 [00:21<00:01, 47.42image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  94%|█████████▍| 949/1006 [00:21<00:01, 46.61image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  95%|█████████▍| 955/1006 [00:21<00:01, 47.56image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  95%|█████████▌| 960/1006 [00:22<00:01, 44.87image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  96%|█████████▌| 965/1006 [00:22<00:01, 39.33image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  96%|█████████▋| 970/1006 [00:22<00:00, 40.65image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  97%|█████████▋| 975/1006 [00:22<00:00, 40.65image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  97%|█████████▋| 980/1006 [00:22<00:00, 41.00image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  98%|█████████▊| 985/1006 [00:22<00:00, 39.97image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  98%|█████████▊| 990/1006 [00:22<00:00, 41.38image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  99%|█████████▉| 995/1006 [00:22<00:00, 40.34image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR: 100%|█████████▉| 1001/1006 [00:23<00:00, 44.17image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR: 100%|██████████| 1006/1006 [00:23<00:00, 43.30image/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average PSNR for perceptual loss extension: 27.936532225284367\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generated_images_path = '/content/idl-project/SimSwap/results-ssim/'\n",
        "source_images_path = '/content/idl-project/SimSwap/combined_images/'\n",
        "\n",
        "average_psnr = compute_average_psnr(generated_images_path, source_images_path)\n",
        "print(\"Average PSNR for SSIMloss extension:\", average_psnr)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2PyVswnAfSaP",
        "outputId": "902d27de-42d6-4d59-bbcb-5f6198ef73d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Calculating PSNR:   0%|          | 0/1006 [00:00<?, ?image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:   0%|          | 5/1006 [00:00<00:22, 45.35image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:   1%|          | 11/1006 [00:00<00:22, 44.16image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:   2%|▏         | 16/1006 [00:00<00:22, 44.57image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:   2%|▏         | 22/1006 [00:00<00:21, 45.43image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:   3%|▎         | 29/1006 [00:00<00:20, 48.62image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:   3%|▎         | 34/1006 [00:00<00:20, 48.25image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:   4%|▍         | 39/1006 [00:00<00:23, 41.64image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:   4%|▍         | 44/1006 [00:01<00:24, 39.09image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:   5%|▌         | 51/1006 [00:01<00:20, 46.38image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:   6%|▌         | 56/1006 [00:01<00:20, 46.68image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:   6%|▌         | 61/1006 [00:01<00:23, 39.57image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:   7%|▋         | 66/1006 [00:01<00:23, 39.50image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:   7%|▋         | 71/1006 [00:01<00:25, 36.45image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:   8%|▊         | 76/1006 [00:01<00:25, 36.03image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:   8%|▊         | 81/1006 [00:01<00:23, 38.57image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:   9%|▊         | 86/1006 [00:02<00:22, 40.29image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:   9%|▉         | 91/1006 [00:02<00:21, 42.64image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  10%|▉         | 96/1006 [00:02<00:20, 43.94image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  10%|█         | 101/1006 [00:02<00:21, 42.31image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  11%|█         | 107/1006 [00:02<00:19, 45.76image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  11%|█         | 112/1006 [00:02<00:19, 45.02image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  12%|█▏        | 117/1006 [00:02<00:19, 45.03image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  12%|█▏        | 123/1006 [00:02<00:18, 47.84image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  13%|█▎        | 129/1006 [00:02<00:18, 46.26image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  13%|█▎        | 134/1006 [00:03<00:18, 46.48image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  14%|█▍        | 142/1006 [00:03<00:16, 53.99image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  15%|█▍        | 148/1006 [00:03<00:16, 51.66image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  15%|█▌        | 154/1006 [00:03<00:15, 53.45image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  16%|█▌        | 160/1006 [00:03<00:16, 51.88image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  17%|█▋        | 166/1006 [00:03<00:16, 50.46image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  17%|█▋        | 172/1006 [00:03<00:17, 46.85image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  18%|█▊        | 177/1006 [00:03<00:18, 45.91image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  18%|█▊        | 182/1006 [00:04<00:18, 45.52image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  19%|█▉        | 189/1006 [00:04<00:16, 49.98image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  19%|█▉        | 195/1006 [00:04<00:15, 51.30image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  20%|█▉        | 201/1006 [00:04<00:15, 50.58image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  21%|██        | 208/1006 [00:04<00:14, 55.50image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  21%|██▏       | 214/1006 [00:04<00:14, 52.98image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  22%|██▏       | 220/1006 [00:04<00:16, 48.52image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  22%|██▏       | 225/1006 [00:04<00:16, 47.79image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  23%|██▎       | 230/1006 [00:05<00:17, 45.36image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  23%|██▎       | 235/1006 [00:05<00:16, 45.88image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  24%|██▍       | 240/1006 [00:05<00:16, 45.76image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  24%|██▍       | 245/1006 [00:05<00:16, 44.84image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  25%|██▍       | 251/1006 [00:05<00:16, 45.12image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  25%|██▌       | 256/1006 [00:05<00:16, 45.60image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  26%|██▌       | 261/1006 [00:05<00:16, 44.06image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  26%|██▋       | 266/1006 [00:05<00:17, 41.87image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  27%|██▋       | 271/1006 [00:05<00:17, 42.35image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  27%|██▋       | 276/1006 [00:06<00:17, 40.93image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  28%|██▊       | 282/1006 [00:06<00:16, 44.77image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  29%|██▊       | 287/1006 [00:06<00:19, 37.71image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  29%|██▉       | 294/1006 [00:06<00:15, 44.87image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  30%|██▉       | 299/1006 [00:06<00:15, 45.55image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  30%|███       | 306/1006 [00:06<00:14, 48.95image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  31%|███       | 312/1006 [00:06<00:13, 51.22image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  32%|███▏      | 319/1006 [00:06<00:12, 54.77image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  32%|███▏      | 325/1006 [00:07<00:12, 54.15image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  33%|███▎      | 331/1006 [00:07<00:12, 52.79image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  34%|███▎      | 338/1006 [00:07<00:12, 51.75image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  34%|███▍      | 344/1006 [00:07<00:14, 46.27image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  35%|███▍      | 349/1006 [00:07<00:14, 45.35image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  35%|███▌      | 355/1006 [00:07<00:14, 44.80image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  36%|███▌      | 360/1006 [00:07<00:14, 44.53image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  36%|███▋      | 365/1006 [00:07<00:14, 45.26image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  37%|███▋      | 370/1006 [00:08<00:16, 38.59image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  37%|███▋      | 377/1006 [00:08<00:13, 45.72image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  38%|███▊      | 382/1006 [00:08<00:14, 42.82image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  39%|███▊      | 388/1006 [00:08<00:14, 43.19image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  39%|███▉      | 393/1006 [00:08<00:14, 43.75image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  40%|███▉      | 400/1006 [00:08<00:12, 48.84image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  40%|████      | 406/1006 [00:08<00:12, 46.73image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  41%|████      | 411/1006 [00:08<00:12, 46.88image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  41%|████▏     | 416/1006 [00:09<00:13, 42.64image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  42%|████▏     | 421/1006 [00:09<00:13, 43.31image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  42%|████▏     | 426/1006 [00:09<00:13, 44.51image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  43%|████▎     | 432/1006 [00:09<00:12, 45.07image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  43%|████▎     | 437/1006 [00:09<00:12, 44.52image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  44%|████▍     | 442/1006 [00:09<00:14, 38.94image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  45%|████▍     | 449/1006 [00:09<00:12, 45.51image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  45%|████▌     | 454/1006 [00:09<00:11, 46.34image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  46%|████▌     | 459/1006 [00:10<00:12, 42.88image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  46%|████▌     | 464/1006 [00:10<00:12, 42.38image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  47%|████▋     | 470/1006 [00:10<00:12, 43.95image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  47%|████▋     | 475/1006 [00:10<00:12, 43.89image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  48%|████▊     | 480/1006 [00:10<00:12, 41.69image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  48%|████▊     | 485/1006 [00:10<00:13, 39.66image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  49%|████▊     | 490/1006 [00:10<00:14, 36.31image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  49%|████▉     | 494/1006 [00:11<00:13, 36.89image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  50%|████▉     | 499/1006 [00:11<00:13, 36.77image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  50%|█████     | 503/1006 [00:11<00:14, 35.27image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  51%|█████     | 509/1006 [00:11<00:12, 40.98image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  51%|█████     | 514/1006 [00:11<00:12, 38.68image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  51%|█████▏    | 518/1006 [00:11<00:12, 38.42image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  52%|█████▏    | 525/1006 [00:11<00:10, 45.98image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  53%|█████▎    | 532/1006 [00:11<00:09, 51.16image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  53%|█████▎    | 538/1006 [00:11<00:09, 50.60image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  54%|█████▍    | 544/1006 [00:12<00:09, 51.14image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  55%|█████▍    | 550/1006 [00:12<00:09, 48.23image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  55%|█████▌    | 555/1006 [00:12<00:09, 47.18image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  56%|█████▌    | 560/1006 [00:12<00:10, 42.46image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  56%|█████▌    | 565/1006 [00:12<00:11, 38.44image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  57%|█████▋    | 570/1006 [00:12<00:10, 40.47image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  57%|█████▋    | 576/1006 [00:12<00:09, 45.12image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  58%|█████▊    | 583/1006 [00:12<00:08, 50.95image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  59%|█████▊    | 589/1006 [00:13<00:09, 45.18image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  59%|█████▉    | 594/1006 [00:13<00:08, 45.83image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  60%|█████▉    | 599/1006 [00:13<00:09, 44.88image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  60%|██████    | 604/1006 [00:13<00:09, 44.25image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  61%|██████    | 609/1006 [00:13<00:09, 39.70image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  61%|██████    | 614/1006 [00:13<00:09, 40.35image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  62%|██████▏   | 619/1006 [00:13<00:09, 42.36image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  62%|██████▏   | 624/1006 [00:13<00:08, 43.93image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  63%|██████▎   | 632/1006 [00:14<00:07, 49.30image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  63%|██████▎   | 638/1006 [00:14<00:07, 47.69image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  64%|██████▍   | 643/1006 [00:14<00:07, 47.68image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  64%|██████▍   | 648/1006 [00:14<00:07, 47.11image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  65%|██████▍   | 653/1006 [00:14<00:07, 46.43image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  65%|██████▌   | 658/1006 [00:14<00:07, 45.52image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  66%|██████▌   | 664/1006 [00:14<00:06, 49.29image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  67%|██████▋   | 669/1006 [00:14<00:07, 43.08image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  67%|██████▋   | 674/1006 [00:15<00:07, 43.03image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  68%|██████▊   | 680/1006 [00:15<00:07, 45.13image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  68%|██████▊   | 685/1006 [00:15<00:08, 39.13image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  69%|██████▊   | 691/1006 [00:15<00:07, 42.82image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  69%|██████▉   | 696/1006 [00:15<00:07, 40.31image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  70%|██████▉   | 702/1006 [00:15<00:07, 43.39image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  70%|███████   | 707/1006 [00:15<00:06, 43.88image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  71%|███████   | 714/1006 [00:15<00:05, 49.23image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  72%|███████▏  | 721/1006 [00:16<00:05, 51.75image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  72%|███████▏  | 729/1006 [00:16<00:05, 55.04image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  73%|███████▎  | 735/1006 [00:16<00:05, 47.74image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  74%|███████▎  | 741/1006 [00:16<00:05, 48.02image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  74%|███████▍  | 746/1006 [00:16<00:05, 47.88image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  75%|███████▍  | 753/1006 [00:16<00:04, 51.00image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  75%|███████▌  | 759/1006 [00:16<00:04, 49.81image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  76%|███████▌  | 765/1006 [00:16<00:05, 43.55image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  77%|███████▋  | 770/1006 [00:17<00:05, 41.96image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  77%|███████▋  | 777/1006 [00:17<00:04, 46.38image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  78%|███████▊  | 782/1006 [00:17<00:04, 46.58image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  78%|███████▊  | 788/1006 [00:17<00:04, 47.71image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  79%|███████▉  | 793/1006 [00:17<00:04, 42.86image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  79%|███████▉  | 798/1006 [00:17<00:04, 41.67image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  80%|███████▉  | 804/1006 [00:17<00:04, 41.75image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  81%|████████  | 811/1006 [00:17<00:04, 47.74image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  81%|████████  | 816/1006 [00:18<00:03, 47.83image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  82%|████████▏ | 823/1006 [00:18<00:03, 46.20image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  82%|████████▏ | 828/1006 [00:18<00:04, 43.90image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  83%|████████▎ | 833/1006 [00:18<00:04, 42.90image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  83%|████████▎ | 838/1006 [00:18<00:04, 40.22image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  84%|████████▍ | 843/1006 [00:18<00:04, 36.84image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  84%|████████▍ | 847/1006 [00:18<00:04, 34.92image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  85%|████████▍ | 853/1006 [00:19<00:03, 39.90image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  85%|████████▌ | 858/1006 [00:19<00:03, 38.92image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  86%|████████▌ | 864/1006 [00:19<00:03, 42.14image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  86%|████████▋ | 869/1006 [00:19<00:03, 42.72image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  87%|████████▋ | 874/1006 [00:19<00:03, 43.15image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  87%|████████▋ | 879/1006 [00:19<00:03, 38.89image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  88%|████████▊ | 887/1006 [00:19<00:02, 48.92image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  89%|████████▉ | 894/1006 [00:19<00:02, 52.37image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  89%|████████▉ | 900/1006 [00:20<00:02, 46.88image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  90%|████████▉ | 905/1006 [00:20<00:02, 42.68image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  90%|█████████ | 910/1006 [00:20<00:02, 39.34image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  91%|█████████ | 915/1006 [00:20<00:02, 38.89image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  92%|█████████▏| 921/1006 [00:20<00:02, 42.22image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  92%|█████████▏| 927/1006 [00:20<00:01, 44.81image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  93%|█████████▎| 932/1006 [00:20<00:01, 44.08image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  93%|█████████▎| 937/1006 [00:20<00:01, 41.44image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  94%|█████████▎| 943/1006 [00:21<00:01, 45.99image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  94%|█████████▍| 948/1006 [00:21<00:01, 44.19image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  95%|█████████▍| 953/1006 [00:21<00:01, 44.89image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  95%|█████████▌| 958/1006 [00:21<00:01, 44.85image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  96%|█████████▌| 963/1006 [00:21<00:00, 44.72image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  96%|█████████▋| 969/1006 [00:21<00:00, 46.42image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  97%|█████████▋| 974/1006 [00:21<00:00, 46.67image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  97%|█████████▋| 980/1006 [00:21<00:00, 47.67image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  98%|█████████▊| 985/1006 [00:22<00:00, 47.78image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  98%|█████████▊| 990/1006 [00:22<00:00, 47.67image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR:  99%|█████████▉| 995/1006 [00:22<00:00, 46.53image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR: 100%|█████████▉| 1001/1006 [00:22<00:00, 45.74image/s]\u001b[A\u001b[A\n",
            "\n",
            "Calculating PSNR: 100%|██████████| 1006/1006 [00:22<00:00, 44.73image/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average PSNR for SSIMloss extension: 27.937053010797335\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "idl-project",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}